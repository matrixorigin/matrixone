set experimental_fulltext_index=1;
set experimental_ivf_index=1;
drop database if exists test_delete;
create database test_delete;
use test_delete;
create table `update_controller_portal5`(
`id` int not null comment 'id',
`mo_table_name` varchar(63) default null,
`dataset_name` varchar(63) not null comment '知识库名称',
`document_name` varchar(63) not null comment '文档名称',
`status` int default null comment '是否调动，1为调动',
`doc_type` int default null,
`target_sql` text not null comment '同步目标sql',
`table_name` varchar(255) not null comment '主表名',
`keys` varchar(255) not null comment '联合键',
`create_at` datetime default current_timestamp(0),
`update_at` datetime default current_timestamp(0),
`dataset_id` varchar(255) default null comment '知识库id',
`ducoment_id` varchar(255) default null comment '文档id',
primary key (`id`),
KEY `this_id`(`id`)
);
insert into update_controller_portal5 values (13, 'aaa', 'aaa', 'aaa', 1, 1, 'select * from table01', 'primary_table', 'key01', '2020-10-10 11:11:11', '2022-10-10 12:12:12', 'dataset', 'document');
select * from update_controller_portal5;
id    mo_table_name    dataset_name    document_name    status    doc_type    target_sql    table_name    keys    create_at    update_at    dataset_id    ducoment_id
13    aaa    aaa    aaa    1    1    select * from table01    primary_table    key01    2020-10-10 11:11:11    2022-10-10 12:12:12    dataset    document
delete from update_controller_portal5 where id = 13;
select * from update_controller_portal5;
id    mo_table_name    dataset_name    document_name    status    doc_type    target_sql    table_name    keys    create_at    update_at    dataset_id    ducoment_id
drop table if exists t1;
create table t1 (a int primary key, b int, c int, d int, e int, f int, g int, key b_idx(b), key c_idx(c), key d_idx(d), key e_idx(d), key f_idx(f), key g_idx(g));
insert into t1 select *,*,*,*,*,*,* from generate_series(0,2000000,1)g;
delete from t1 where a < 1000002 and a > 1000000;
drop table if exists ca_comprehensive_dataset;
create table ca_comprehensive_dataset (
id           int primary key,
answer       json,
delete_flag  tinyint not null default 0
);
insert into ca_comprehensive_dataset values
(1 , '{"document":"多层级专题.txt"}', 1),
(2 , '{"document":"多层级专题.txt"}', 0),
(3 , '{"document":"其他.txt"}', 1),
(4 , '{"meta":{"document":"多层级专题.txt"}}', 1),
(5 , '{"document":null}', 1),
(6 , '{"document":["多层级专题.txt","a.txt"]}', 1),
(7 , '{"document":" 多层级专题.txt "}', 1),
(8 , '{"document":"多层级专题.TXT"}', 1),
(9 , '{"document":"多层级专题.txt"}', 1),
(10, '{"title":"something"}', 1),
(11, '{"document":true}', 1);
select id, delete_flag, json_unquote(json_extract(answer,'$.document')) as doc
from ca_comprehensive_dataset order by id;
id    delete_flag    doc
1    1    多层级专题.txt
2    0    多层级专题.txt
3    1    其他.txt
4    1    null
5    1    null
6    1    ["多层级专题.txt", "a.txt"]
7    1     多层级专题.txt 
8    1    多层级专题.TXT
9    1    多层级专题.txt
10    1    null
11    1    true
delete from ca_comprehensive_dataset
where json_unquote(json_extract(answer, '$.document')) = '多层级专题.txt'
and delete_flag = 1;
select count(*) as remain from ca_comprehensive_dataset;          -- 总数校验
remain
9
select group_concat(id order by id) as left_ids from ca_comprehensive_dataset;
left_ids
2,3,4,5,6,7,8,10,11
delete from ca_comprehensive_dataset
where trim(json_unquote(json_extract(answer, '$.document'))) = '多层级专题.txt'
and delete_flag = 1;
delete from ca_comprehensive_dataset
where json_unquote(json_extract(answer, '$.document')) is null
and delete_flag = 1;
delete from ca_comprehensive_dataset
where lower(json_unquote(json_extract(answer, '$.document'))) = lower('多层级专题.TXT')
and delete_flag = 1;
prepare del_stmt from
'delete from ca_comprehensive_dataset
where json_unquote(json_extract(answer, ''$.document'')) = ?
and delete_flag = 1';
set @doc := '其他.txt';
execute del_stmt using @doc;
deallocate prepare del_stmt;
select id, delete_flag, json_unquote(json_extract(answer,'$.document')) as doc
from ca_comprehensive_dataset order by id;
id    delete_flag    doc
2    0    多层级专题.txt
6    1    ["多层级专题.txt", "a.txt"]
11    1    true
DROP TABLE IF EXISTS `ca_comprehensive_dataset`;
CREATE TABLE `ca_comprehensive_dataset` (
`md5_id` varchar(255) NOT NULL,
`question` text DEFAULT NULL,
`answer` json DEFAULT NULL,
`source_type` varchar(255) DEFAULT NULL,
`content_type` varchar(255) DEFAULT NULL,
`keyword` varchar(255) DEFAULT NULL,
`question_vector` vecf64(1024) DEFAULT NULL COMMENT '摘要的向量集',
`allow_access` varchar(511) DEFAULT NULL,
`allow_identities` varchar(512) DEFAULT NULL,
`delete_flag` int DEFAULT NULL,
`created_at` timestamp DEFAULT CURRENT_TIMESTAMP(),
`updated_at` timestamp DEFAULT CURRENT_TIMESTAMP() ON UPDATE CURRENT_TIMESTAMP(),
PRIMARY KEY (`md5_id`),
FULLTEXT `idx_ft_question`(`question`) WITH PARSER ngram,
KEY `idx_vec_question` USING ivfflat (`question_vector`) lists = 256  op_type 'vector_l2_ops' ,
KEY `idx_comprehensive_allow_access` (`allow_access`),
KEY `idx_comprehensive_allow_identities` (`allow_identities`),
KEY `idx_comprehensive_content_type` (`content_type`)
);
delete from ca_comprehensive_dataset limit 1;
drop table if exists update_controller_portal5;
create table update_controller_portal5 (
id int not null,
payload varchar(50) default null,
primary key (id),
key idx_this_id (id)
);
insert into update_controller_portal5 (id, payload) values (13, 'row-13');
delete from update_controller_portal5 where id = 13;
select count(*) as remaining from update_controller_portal5 where id = 13;
remaining
0
drop table if exists t_dup_idx;
create table t_dup_idx (
id int not null,
payload varchar(50) default null,
primary key (id)
);
insert into t_dup_idx (id, payload) values (1, 'a'), (2, 'b');
create index idx_dup on t_dup_idx (id);
delete from t_dup_idx where id = 2;
select group_concat(id order by id) as remaining_ids from t_dup_idx;
remaining_ids
1
drop database test_delete;
