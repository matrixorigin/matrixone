// Code generated by command: go run avx512.go -out avx512.s -stubs avx512_stubs.go. DO NOT EDIT.

#include "textflag.h"

// func int8MaxAvx512Asm(x []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, SSE2, SSE4.1
TEXT ·int8MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0x0000000000000080, BX
	MOVQ         BX, X0
	VPBROADCASTB X0, Z0
	VMOVDQU64    Z0, Z1
	VMOVDQU64    Z0, Z2
	VMOVDQU64    Z0, Z3
	VMOVDQU64    Z0, Z4
	VMOVDQU64    Z0, Z5
	VMOVDQU64    Z0, Z6
	VMOVDQU64    Z0, Z7
	VMOVDQU64    Z0, Z8
	VMOVDQU64    Z0, Z9
	VMOVDQU64    Z0, Z10
	VMOVDQU64    Z0, Z11
	VMOVDQU64    Z0, Z0

int8MaxBlockLoop:
	CMPQ    DX, $0x00000300
	JL      int8MaxTailLoop
	VPMAXSB (AX), Z1, Z1
	VPMAXSB 64(AX), Z2, Z2
	VPMAXSB 128(AX), Z3, Z3
	VPMAXSB 192(AX), Z4, Z4
	VPMAXSB 256(AX), Z5, Z5
	VPMAXSB 320(AX), Z6, Z6
	VPMAXSB 384(AX), Z7, Z7
	VPMAXSB 448(AX), Z8, Z8
	VPMAXSB 512(AX), Z9, Z9
	VPMAXSB 576(AX), Z10, Z10
	VPMAXSB 640(AX), Z11, Z11
	VPMAXSB 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x00000300, DX
	JMP     int8MaxBlockLoop

int8MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      int8MaxDone
	VPMAXSB (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000040, DX
	JMP     int8MaxTailLoop

int8MaxDone:
	VPMAXSB       Z1, Z2, Z1
	VPMAXSB       Z1, Z3, Z1
	VPMAXSB       Z1, Z4, Z1
	VPMAXSB       Z1, Z5, Z1
	VPMAXSB       Z1, Z6, Z1
	VPMAXSB       Z1, Z7, Z1
	VPMAXSB       Z1, Z8, Z1
	VPMAXSB       Z1, Z9, Z1
	VPMAXSB       Z1, Z10, Z1
	VPMAXSB       Z1, Z11, Z1
	VPMAXSB       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXSB       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	PMAXSB        X0, X1
	MOVOU         X1, (CX)
	RET

// func int16MaxAvx512Asm(x []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, SSE2
TEXT ·int16MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0x0000000000008000, BX
	MOVQ         BX, X0
	VPBROADCASTW X0, Z0
	VMOVDQU64    Z0, Z1
	VMOVDQU64    Z0, Z2
	VMOVDQU64    Z0, Z3
	VMOVDQU64    Z0, Z4
	VMOVDQU64    Z0, Z5
	VMOVDQU64    Z0, Z6
	VMOVDQU64    Z0, Z7
	VMOVDQU64    Z0, Z8
	VMOVDQU64    Z0, Z9
	VMOVDQU64    Z0, Z10
	VMOVDQU64    Z0, Z11
	VMOVDQU64    Z0, Z0

int16MaxBlockLoop:
	CMPQ    DX, $0x00000180
	JL      int16MaxTailLoop
	VPMAXSW (AX), Z1, Z1
	VPMAXSW 64(AX), Z2, Z2
	VPMAXSW 128(AX), Z3, Z3
	VPMAXSW 192(AX), Z4, Z4
	VPMAXSW 256(AX), Z5, Z5
	VPMAXSW 320(AX), Z6, Z6
	VPMAXSW 384(AX), Z7, Z7
	VPMAXSW 448(AX), Z8, Z8
	VPMAXSW 512(AX), Z9, Z9
	VPMAXSW 576(AX), Z10, Z10
	VPMAXSW 640(AX), Z11, Z11
	VPMAXSW 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x00000180, DX
	JMP     int16MaxBlockLoop

int16MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      int16MaxDone
	VPMAXSW (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000020, DX
	JMP     int16MaxTailLoop

int16MaxDone:
	VPMAXSW       Z1, Z2, Z1
	VPMAXSW       Z1, Z3, Z1
	VPMAXSW       Z1, Z4, Z1
	VPMAXSW       Z1, Z5, Z1
	VPMAXSW       Z1, Z6, Z1
	VPMAXSW       Z1, Z7, Z1
	VPMAXSW       Z1, Z8, Z1
	VPMAXSW       Z1, Z9, Z1
	VPMAXSW       Z1, Z10, Z1
	VPMAXSW       Z1, Z11, Z1
	VPMAXSW       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXSW       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	PMAXSW        X0, X1
	MOVOU         X1, (CX)
	RET

// func int32MaxAvx512Asm(x []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, SSE2, SSE4.1
TEXT ·int32MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0x0000000080000000, BX
	MOVQ         BX, X0
	VPBROADCASTD X0, Z0
	VMOVDQU64    Z0, Z1
	VMOVDQU64    Z0, Z2
	VMOVDQU64    Z0, Z3
	VMOVDQU64    Z0, Z4
	VMOVDQU64    Z0, Z5
	VMOVDQU64    Z0, Z6
	VMOVDQU64    Z0, Z7
	VMOVDQU64    Z0, Z8
	VMOVDQU64    Z0, Z9
	VMOVDQU64    Z0, Z10
	VMOVDQU64    Z0, Z11
	VMOVDQU64    Z0, Z0

int32MaxBlockLoop:
	CMPQ    DX, $0x000000c0
	JL      int32MaxTailLoop
	VPMAXSD (AX), Z1, Z1
	VPMAXSD 64(AX), Z2, Z2
	VPMAXSD 128(AX), Z3, Z3
	VPMAXSD 192(AX), Z4, Z4
	VPMAXSD 256(AX), Z5, Z5
	VPMAXSD 320(AX), Z6, Z6
	VPMAXSD 384(AX), Z7, Z7
	VPMAXSD 448(AX), Z8, Z8
	VPMAXSD 512(AX), Z9, Z9
	VPMAXSD 576(AX), Z10, Z10
	VPMAXSD 640(AX), Z11, Z11
	VPMAXSD 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x000000c0, DX
	JMP     int32MaxBlockLoop

int32MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      int32MaxDone
	VPMAXSD (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000010, DX
	JMP     int32MaxTailLoop

int32MaxDone:
	VPMAXSD       Z1, Z2, Z1
	VPMAXSD       Z1, Z3, Z1
	VPMAXSD       Z1, Z4, Z1
	VPMAXSD       Z1, Z5, Z1
	VPMAXSD       Z1, Z6, Z1
	VPMAXSD       Z1, Z7, Z1
	VPMAXSD       Z1, Z8, Z1
	VPMAXSD       Z1, Z9, Z1
	VPMAXSD       Z1, Z10, Z1
	VPMAXSD       Z1, Z11, Z1
	VPMAXSD       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXSD       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	PMAXSD        X0, X1
	MOVOU         X1, (CX)
	RET

// func int64MaxAvx512Asm(x []int64, r []int64)
// Requires: AVX, AVX512F, AVX512VL, SSE2
TEXT ·int64MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0x8000000000000000, BX
	MOVQ         BX, X0
	VPBROADCASTQ X0, Z0
	VMOVDQU64    Z0, Z1
	VMOVDQU64    Z0, Z2
	VMOVDQU64    Z0, Z3
	VMOVDQU64    Z0, Z4
	VMOVDQU64    Z0, Z5
	VMOVDQU64    Z0, Z6
	VMOVDQU64    Z0, Z7
	VMOVDQU64    Z0, Z8
	VMOVDQU64    Z0, Z9
	VMOVDQU64    Z0, Z10
	VMOVDQU64    Z0, Z11
	VMOVDQU64    Z0, Z0

int64MaxBlockLoop:
	CMPQ    DX, $0x00000060
	JL      int64MaxTailLoop
	VPMAXSQ (AX), Z1, Z1
	VPMAXSQ 64(AX), Z2, Z2
	VPMAXSQ 128(AX), Z3, Z3
	VPMAXSQ 192(AX), Z4, Z4
	VPMAXSQ 256(AX), Z5, Z5
	VPMAXSQ 320(AX), Z6, Z6
	VPMAXSQ 384(AX), Z7, Z7
	VPMAXSQ 448(AX), Z8, Z8
	VPMAXSQ 512(AX), Z9, Z9
	VPMAXSQ 576(AX), Z10, Z10
	VPMAXSQ 640(AX), Z11, Z11
	VPMAXSQ 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x00000060, DX
	JMP     int64MaxBlockLoop

int64MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      int64MaxDone
	VPMAXSQ (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000008, DX
	JMP     int64MaxTailLoop

int64MaxDone:
	VPMAXSQ       Z1, Z2, Z1
	VPMAXSQ       Z1, Z3, Z1
	VPMAXSQ       Z1, Z4, Z1
	VPMAXSQ       Z1, Z5, Z1
	VPMAXSQ       Z1, Z6, Z1
	VPMAXSQ       Z1, Z7, Z1
	VPMAXSQ       Z1, Z8, Z1
	VPMAXSQ       Z1, Z9, Z1
	VPMAXSQ       Z1, Z10, Z1
	VPMAXSQ       Z1, Z11, Z1
	VPMAXSQ       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXSQ       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	VPMAXSQ       X0, X1, X1
	MOVOU         X1, (CX)
	RET

// func uint8MaxAvx512Asm(x []uint8, r []uint8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, SSE2
TEXT ·uint8MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORQ Z0, Z0, Z0
	VPXORQ Z1, Z1, Z1
	VPXORQ Z2, Z2, Z2
	VPXORQ Z3, Z3, Z3
	VPXORQ Z4, Z4, Z4
	VPXORQ Z5, Z5, Z5
	VPXORQ Z6, Z6, Z6
	VPXORQ Z7, Z7, Z7
	VPXORQ Z8, Z8, Z8
	VPXORQ Z9, Z9, Z9
	VPXORQ Z10, Z10, Z10
	VPXORQ Z11, Z11, Z11

uint8MaxBlockLoop:
	CMPQ    DX, $0x00000300
	JL      uint8MaxTailLoop
	VPMAXUB (AX), Z1, Z1
	VPMAXUB 64(AX), Z2, Z2
	VPMAXUB 128(AX), Z3, Z3
	VPMAXUB 192(AX), Z4, Z4
	VPMAXUB 256(AX), Z5, Z5
	VPMAXUB 320(AX), Z6, Z6
	VPMAXUB 384(AX), Z7, Z7
	VPMAXUB 448(AX), Z8, Z8
	VPMAXUB 512(AX), Z9, Z9
	VPMAXUB 576(AX), Z10, Z10
	VPMAXUB 640(AX), Z11, Z11
	VPMAXUB 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x00000300, DX
	JMP     uint8MaxBlockLoop

uint8MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      uint8MaxDone
	VPMAXUB (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000040, DX
	JMP     uint8MaxTailLoop

uint8MaxDone:
	VPMAXUB       Z1, Z2, Z1
	VPMAXUB       Z1, Z3, Z1
	VPMAXUB       Z1, Z4, Z1
	VPMAXUB       Z1, Z5, Z1
	VPMAXUB       Z1, Z6, Z1
	VPMAXUB       Z1, Z7, Z1
	VPMAXUB       Z1, Z8, Z1
	VPMAXUB       Z1, Z9, Z1
	VPMAXUB       Z1, Z10, Z1
	VPMAXUB       Z1, Z11, Z1
	VPMAXUB       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXUB       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	PMAXUB        X0, X1
	MOVOU         X1, (CX)
	RET

// func uint16MaxAvx512Asm(x []uint16, r []uint16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, SSE2, SSE4.1
TEXT ·uint16MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORQ Z0, Z0, Z0
	VPXORQ Z1, Z1, Z1
	VPXORQ Z2, Z2, Z2
	VPXORQ Z3, Z3, Z3
	VPXORQ Z4, Z4, Z4
	VPXORQ Z5, Z5, Z5
	VPXORQ Z6, Z6, Z6
	VPXORQ Z7, Z7, Z7
	VPXORQ Z8, Z8, Z8
	VPXORQ Z9, Z9, Z9
	VPXORQ Z10, Z10, Z10
	VPXORQ Z11, Z11, Z11

uint16MaxBlockLoop:
	CMPQ    DX, $0x00000180
	JL      uint16MaxTailLoop
	VPMAXUW (AX), Z1, Z1
	VPMAXUW 64(AX), Z2, Z2
	VPMAXUW 128(AX), Z3, Z3
	VPMAXUW 192(AX), Z4, Z4
	VPMAXUW 256(AX), Z5, Z5
	VPMAXUW 320(AX), Z6, Z6
	VPMAXUW 384(AX), Z7, Z7
	VPMAXUW 448(AX), Z8, Z8
	VPMAXUW 512(AX), Z9, Z9
	VPMAXUW 576(AX), Z10, Z10
	VPMAXUW 640(AX), Z11, Z11
	VPMAXUW 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x00000180, DX
	JMP     uint16MaxBlockLoop

uint16MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      uint16MaxDone
	VPMAXUW (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000020, DX
	JMP     uint16MaxTailLoop

uint16MaxDone:
	VPMAXUW       Z1, Z2, Z1
	VPMAXUW       Z1, Z3, Z1
	VPMAXUW       Z1, Z4, Z1
	VPMAXUW       Z1, Z5, Z1
	VPMAXUW       Z1, Z6, Z1
	VPMAXUW       Z1, Z7, Z1
	VPMAXUW       Z1, Z8, Z1
	VPMAXUW       Z1, Z9, Z1
	VPMAXUW       Z1, Z10, Z1
	VPMAXUW       Z1, Z11, Z1
	VPMAXUW       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXUW       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	PMAXUW        X0, X1
	MOVOU         X1, (CX)
	RET

// func uint32MaxAvx512Asm(x []uint32, r []uint32)
// Requires: AVX, AVX2, AVX512F, SSE2, SSE4.1
TEXT ·uint32MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORQ Z0, Z0, Z0
	VPXORQ Z1, Z1, Z1
	VPXORQ Z2, Z2, Z2
	VPXORQ Z3, Z3, Z3
	VPXORQ Z4, Z4, Z4
	VPXORQ Z5, Z5, Z5
	VPXORQ Z6, Z6, Z6
	VPXORQ Z7, Z7, Z7
	VPXORQ Z8, Z8, Z8
	VPXORQ Z9, Z9, Z9
	VPXORQ Z10, Z10, Z10
	VPXORQ Z11, Z11, Z11

uint32MaxBlockLoop:
	CMPQ    DX, $0x000000c0
	JL      uint32MaxTailLoop
	VPMAXUD (AX), Z1, Z1
	VPMAXUD 64(AX), Z2, Z2
	VPMAXUD 128(AX), Z3, Z3
	VPMAXUD 192(AX), Z4, Z4
	VPMAXUD 256(AX), Z5, Z5
	VPMAXUD 320(AX), Z6, Z6
	VPMAXUD 384(AX), Z7, Z7
	VPMAXUD 448(AX), Z8, Z8
	VPMAXUD 512(AX), Z9, Z9
	VPMAXUD 576(AX), Z10, Z10
	VPMAXUD 640(AX), Z11, Z11
	VPMAXUD 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x000000c0, DX
	JMP     uint32MaxBlockLoop

uint32MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      uint32MaxDone
	VPMAXUD (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000010, DX
	JMP     uint32MaxTailLoop

uint32MaxDone:
	VPMAXUD       Z1, Z2, Z1
	VPMAXUD       Z1, Z3, Z1
	VPMAXUD       Z1, Z4, Z1
	VPMAXUD       Z1, Z5, Z1
	VPMAXUD       Z1, Z6, Z1
	VPMAXUD       Z1, Z7, Z1
	VPMAXUD       Z1, Z8, Z1
	VPMAXUD       Z1, Z9, Z1
	VPMAXUD       Z1, Z10, Z1
	VPMAXUD       Z1, Z11, Z1
	VPMAXUD       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXUD       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	PMAXUD        X0, X1
	MOVOU         X1, (CX)
	RET

// func uint64MaxAvx512Asm(x []uint64, r []uint64)
// Requires: AVX, AVX512F, AVX512VL, SSE2
TEXT ·uint64MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORQ Z0, Z0, Z0
	VPXORQ Z1, Z1, Z1
	VPXORQ Z2, Z2, Z2
	VPXORQ Z3, Z3, Z3
	VPXORQ Z4, Z4, Z4
	VPXORQ Z5, Z5, Z5
	VPXORQ Z6, Z6, Z6
	VPXORQ Z7, Z7, Z7
	VPXORQ Z8, Z8, Z8
	VPXORQ Z9, Z9, Z9
	VPXORQ Z10, Z10, Z10
	VPXORQ Z11, Z11, Z11

uint64MaxBlockLoop:
	CMPQ    DX, $0x00000060
	JL      uint64MaxTailLoop
	VPMAXUQ (AX), Z1, Z1
	VPMAXUQ 64(AX), Z2, Z2
	VPMAXUQ 128(AX), Z3, Z3
	VPMAXUQ 192(AX), Z4, Z4
	VPMAXUQ 256(AX), Z5, Z5
	VPMAXUQ 320(AX), Z6, Z6
	VPMAXUQ 384(AX), Z7, Z7
	VPMAXUQ 448(AX), Z8, Z8
	VPMAXUQ 512(AX), Z9, Z9
	VPMAXUQ 576(AX), Z10, Z10
	VPMAXUQ 640(AX), Z11, Z11
	VPMAXUQ 704(AX), Z0, Z0
	ADDQ    $0x00000300, AX
	SUBQ    $0x00000060, DX
	JMP     uint64MaxBlockLoop

uint64MaxTailLoop:
	CMPQ    DX, $0x00000004
	JL      uint64MaxDone
	VPMAXUQ (AX), Z1, Z1
	ADDQ    $0x00000040, AX
	SUBQ    $0x00000008, DX
	JMP     uint64MaxTailLoop

uint64MaxDone:
	VPMAXUQ       Z1, Z2, Z1
	VPMAXUQ       Z1, Z3, Z1
	VPMAXUQ       Z1, Z4, Z1
	VPMAXUQ       Z1, Z5, Z1
	VPMAXUQ       Z1, Z6, Z1
	VPMAXUQ       Z1, Z7, Z1
	VPMAXUQ       Z1, Z8, Z1
	VPMAXUQ       Z1, Z9, Z1
	VPMAXUQ       Z1, Z10, Z1
	VPMAXUQ       Z1, Z11, Z1
	VPMAXUQ       Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VPMAXUQ       Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	VPMAXUQ       X0, X1, X1
	MOVOU         X1, (CX)
	RET

// func float32MaxAvx512Asm(x []float32, r []float32)
// Requires: AVX, AVX512F, SSE, SSE2
TEXT ·float32MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0x00000000ff7fffff, BX
	MOVQ         BX, X0
	VBROADCASTSS X0, Z0
	VMOVUPS      Z0, Z1
	VMOVUPS      Z0, Z2
	VMOVUPS      Z0, Z3
	VMOVUPS      Z0, Z4
	VMOVUPS      Z0, Z5
	VMOVUPS      Z0, Z6
	VMOVUPS      Z0, Z7
	VMOVUPS      Z0, Z8
	VMOVUPS      Z0, Z9
	VMOVUPS      Z0, Z10
	VMOVUPS      Z0, Z11
	VMOVUPS      Z0, Z0

float32MaxBlockLoop:
	CMPQ   DX, $0x000000c0
	JL     float32MaxTailLoop
	VMAXPS (AX), Z1, Z1
	VMAXPS 64(AX), Z2, Z2
	VMAXPS 128(AX), Z3, Z3
	VMAXPS 192(AX), Z4, Z4
	VMAXPS 256(AX), Z5, Z5
	VMAXPS 320(AX), Z6, Z6
	VMAXPS 384(AX), Z7, Z7
	VMAXPS 448(AX), Z8, Z8
	VMAXPS 512(AX), Z9, Z9
	VMAXPS 576(AX), Z10, Z10
	VMAXPS 640(AX), Z11, Z11
	VMAXPS 704(AX), Z0, Z0
	ADDQ   $0x00000300, AX
	SUBQ   $0x000000c0, DX
	JMP    float32MaxBlockLoop

float32MaxTailLoop:
	CMPQ   DX, $0x00000004
	JL     float32MaxDone
	VMAXPS (AX), Z1, Z1
	ADDQ   $0x00000040, AX
	SUBQ   $0x00000010, DX
	JMP    float32MaxTailLoop

float32MaxDone:
	VMAXPS        Z1, Z2, Z1
	VMAXPS        Z1, Z3, Z1
	VMAXPS        Z1, Z4, Z1
	VMAXPS        Z1, Z5, Z1
	VMAXPS        Z1, Z6, Z1
	VMAXPS        Z1, Z7, Z1
	VMAXPS        Z1, Z8, Z1
	VMAXPS        Z1, Z9, Z1
	VMAXPS        Z1, Z10, Z1
	VMAXPS        Z1, Z11, Z1
	VMAXPS        Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VMAXPS        Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	MAXPS         X0, X1
	MOVOU         X1, (CX)
	RET

// func float64MaxAvx512Asm(x []float64, r []float64)
// Requires: AVX, AVX512F, SSE2
TEXT ·float64MaxAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0xffefffffffffffff, BX
	MOVQ         BX, X0
	VBROADCASTSD X0, Z0
	VMOVUPD      Z0, Z1
	VMOVUPD      Z0, Z2
	VMOVUPD      Z0, Z3
	VMOVUPD      Z0, Z4
	VMOVUPD      Z0, Z5
	VMOVUPD      Z0, Z6
	VMOVUPD      Z0, Z7
	VMOVUPD      Z0, Z8
	VMOVUPD      Z0, Z9
	VMOVUPD      Z0, Z10
	VMOVUPD      Z0, Z11
	VMOVUPD      Z0, Z0

float64MaxBlockLoop:
	CMPQ   DX, $0x00000060
	JL     float64MaxTailLoop
	VMAXPD (AX), Z1, Z1
	VMAXPD 64(AX), Z2, Z2
	VMAXPD 128(AX), Z3, Z3
	VMAXPD 192(AX), Z4, Z4
	VMAXPD 256(AX), Z5, Z5
	VMAXPD 320(AX), Z6, Z6
	VMAXPD 384(AX), Z7, Z7
	VMAXPD 448(AX), Z8, Z8
	VMAXPD 512(AX), Z9, Z9
	VMAXPD 576(AX), Z10, Z10
	VMAXPD 640(AX), Z11, Z11
	VMAXPD 704(AX), Z0, Z0
	ADDQ   $0x00000300, AX
	SUBQ   $0x00000060, DX
	JMP    float64MaxBlockLoop

float64MaxTailLoop:
	CMPQ   DX, $0x00000004
	JL     float64MaxDone
	VMAXPD (AX), Z1, Z1
	ADDQ   $0x00000040, AX
	SUBQ   $0x00000008, DX
	JMP    float64MaxTailLoop

float64MaxDone:
	VMAXPD        Z1, Z2, Z1
	VMAXPD        Z1, Z3, Z1
	VMAXPD        Z1, Z4, Z1
	VMAXPD        Z1, Z5, Z1
	VMAXPD        Z1, Z6, Z1
	VMAXPD        Z1, Z7, Z1
	VMAXPD        Z1, Z8, Z1
	VMAXPD        Z1, Z9, Z1
	VMAXPD        Z1, Z10, Z1
	VMAXPD        Z1, Z11, Z1
	VMAXPD        Z1, Z0, Z1
	VEXTRACTI64X4 $0x01, Z1, Y0
	VMAXPD        Y0, Y1, Y1
	VEXTRACTF128  $0x01, Y1, X0
	MAXPD         X0, X1
	MOVOU         X1, (CX)
	RET
