// Code generated by command: go run avx512.go -out avx512.s -stubs avx512_stubs.go. DO NOT EDIT.
// +build amd64

#include "textflag.h"

// func int8NegAvx512Asm(x []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·int8NegAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORD Z0, Z0, Z0

int8NegBlockLoop:
	CMPQ      DX, $0x000007c0
	JL        int8NegTailLoop
	VPSUBB    (AX), Z0, Z1
	VPSUBB    64(AX), Z0, Z2
	VPSUBB    128(AX), Z0, Z3
	VPSUBB    192(AX), Z0, Z4
	VPSUBB    256(AX), Z0, Z5
	VPSUBB    320(AX), Z0, Z6
	VPSUBB    384(AX), Z0, Z7
	VPSUBB    448(AX), Z0, Z8
	VPSUBB    512(AX), Z0, Z9
	VPSUBB    576(AX), Z0, Z10
	VPSUBB    640(AX), Z0, Z11
	VPSUBB    704(AX), Z0, Z12
	VPSUBB    768(AX), Z0, Z13
	VPSUBB    832(AX), Z0, Z14
	VPSUBB    896(AX), Z0, Z15
	VPSUBB    960(AX), Z0, Z16
	VPSUBB    1024(AX), Z0, Z17
	VPSUBB    1088(AX), Z0, Z18
	VPSUBB    1152(AX), Z0, Z19
	VPSUBB    1216(AX), Z0, Z20
	VPSUBB    1280(AX), Z0, Z21
	VPSUBB    1344(AX), Z0, Z22
	VPSUBB    1408(AX), Z0, Z23
	VPSUBB    1472(AX), Z0, Z24
	VPSUBB    1536(AX), Z0, Z25
	VPSUBB    1600(AX), Z0, Z26
	VPSUBB    1664(AX), Z0, Z27
	VPSUBB    1728(AX), Z0, Z28
	VPSUBB    1792(AX), Z0, Z29
	VPSUBB    1856(AX), Z0, Z30
	VPSUBB    1920(AX), Z0, Z31
	VMOVDQU32 Z1, (CX)
	VMOVDQU32 Z2, 64(CX)
	VMOVDQU32 Z3, 128(CX)
	VMOVDQU32 Z4, 192(CX)
	VMOVDQU32 Z5, 256(CX)
	VMOVDQU32 Z6, 320(CX)
	VMOVDQU32 Z7, 384(CX)
	VMOVDQU32 Z8, 448(CX)
	VMOVDQU32 Z9, 512(CX)
	VMOVDQU32 Z10, 576(CX)
	VMOVDQU32 Z11, 640(CX)
	VMOVDQU32 Z12, 704(CX)
	VMOVDQU32 Z13, 768(CX)
	VMOVDQU32 Z14, 832(CX)
	VMOVDQU32 Z15, 896(CX)
	VMOVDQU32 Z16, 960(CX)
	VMOVDQU32 Z17, 1024(CX)
	VMOVDQU32 Z18, 1088(CX)
	VMOVDQU32 Z19, 1152(CX)
	VMOVDQU32 Z20, 1216(CX)
	VMOVDQU32 Z21, 1280(CX)
	VMOVDQU32 Z22, 1344(CX)
	VMOVDQU32 Z23, 1408(CX)
	VMOVDQU32 Z24, 1472(CX)
	VMOVDQU32 Z25, 1536(CX)
	VMOVDQU32 Z26, 1600(CX)
	VMOVDQU32 Z27, 1664(CX)
	VMOVDQU32 Z28, 1728(CX)
	VMOVDQU32 Z29, 1792(CX)
	VMOVDQU32 Z30, 1856(CX)
	VMOVDQU32 Z31, 1920(CX)
	ADDQ      $0x000007c0, AX
	ADDQ      $0x000007c0, CX
	SUBQ      $0x000007c0, DX
	JMP       int8NegBlockLoop

int8NegTailLoop:
	CMPQ      DX, $0x00000040
	JL        int8NegDone
	VPSUBB    (AX), Z0, Z1
	VMOVDQU32 Z1, (CX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, DX
	JMP       int8NegTailLoop

int8NegDone:
	CMPQ      DX, $0x00000020
	JL        int8NegDone1
	VPSUBB    (AX), Y0, Y1
	VMOVDQU32 Y1, (CX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	SUBQ      $0x00000020, DX

int8NegDone1:
	CMPQ      DX, $0x00000010
	JL        int8NegDone2
	VPSUBB    (AX), X0, X1
	VMOVDQU32 X1, (CX)

int8NegDone2:
	RET

// func int16NegAvx512Asm(x []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·int16NegAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORD Z0, Z0, Z0

int16NegBlockLoop:
	CMPQ      DX, $0x000003e0
	JL        int16NegTailLoop
	VPSUBW    (AX), Z0, Z1
	VPSUBW    64(AX), Z0, Z2
	VPSUBW    128(AX), Z0, Z3
	VPSUBW    192(AX), Z0, Z4
	VPSUBW    256(AX), Z0, Z5
	VPSUBW    320(AX), Z0, Z6
	VPSUBW    384(AX), Z0, Z7
	VPSUBW    448(AX), Z0, Z8
	VPSUBW    512(AX), Z0, Z9
	VPSUBW    576(AX), Z0, Z10
	VPSUBW    640(AX), Z0, Z11
	VPSUBW    704(AX), Z0, Z12
	VPSUBW    768(AX), Z0, Z13
	VPSUBW    832(AX), Z0, Z14
	VPSUBW    896(AX), Z0, Z15
	VPSUBW    960(AX), Z0, Z16
	VPSUBW    1024(AX), Z0, Z17
	VPSUBW    1088(AX), Z0, Z18
	VPSUBW    1152(AX), Z0, Z19
	VPSUBW    1216(AX), Z0, Z20
	VPSUBW    1280(AX), Z0, Z21
	VPSUBW    1344(AX), Z0, Z22
	VPSUBW    1408(AX), Z0, Z23
	VPSUBW    1472(AX), Z0, Z24
	VPSUBW    1536(AX), Z0, Z25
	VPSUBW    1600(AX), Z0, Z26
	VPSUBW    1664(AX), Z0, Z27
	VPSUBW    1728(AX), Z0, Z28
	VPSUBW    1792(AX), Z0, Z29
	VPSUBW    1856(AX), Z0, Z30
	VPSUBW    1920(AX), Z0, Z31
	VMOVDQU32 Z1, (CX)
	VMOVDQU32 Z2, 64(CX)
	VMOVDQU32 Z3, 128(CX)
	VMOVDQU32 Z4, 192(CX)
	VMOVDQU32 Z5, 256(CX)
	VMOVDQU32 Z6, 320(CX)
	VMOVDQU32 Z7, 384(CX)
	VMOVDQU32 Z8, 448(CX)
	VMOVDQU32 Z9, 512(CX)
	VMOVDQU32 Z10, 576(CX)
	VMOVDQU32 Z11, 640(CX)
	VMOVDQU32 Z12, 704(CX)
	VMOVDQU32 Z13, 768(CX)
	VMOVDQU32 Z14, 832(CX)
	VMOVDQU32 Z15, 896(CX)
	VMOVDQU32 Z16, 960(CX)
	VMOVDQU32 Z17, 1024(CX)
	VMOVDQU32 Z18, 1088(CX)
	VMOVDQU32 Z19, 1152(CX)
	VMOVDQU32 Z20, 1216(CX)
	VMOVDQU32 Z21, 1280(CX)
	VMOVDQU32 Z22, 1344(CX)
	VMOVDQU32 Z23, 1408(CX)
	VMOVDQU32 Z24, 1472(CX)
	VMOVDQU32 Z25, 1536(CX)
	VMOVDQU32 Z26, 1600(CX)
	VMOVDQU32 Z27, 1664(CX)
	VMOVDQU32 Z28, 1728(CX)
	VMOVDQU32 Z29, 1792(CX)
	VMOVDQU32 Z30, 1856(CX)
	VMOVDQU32 Z31, 1920(CX)
	ADDQ      $0x000007c0, AX
	ADDQ      $0x000007c0, CX
	SUBQ      $0x000003e0, DX
	JMP       int16NegBlockLoop

int16NegTailLoop:
	CMPQ      DX, $0x00000020
	JL        int16NegDone
	VPSUBW    (AX), Z0, Z1
	VMOVDQU32 Z1, (CX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000020, DX
	JMP       int16NegTailLoop

int16NegDone:
	CMPQ      DX, $0x00000010
	JL        int16NegDone1
	VPSUBW    (AX), Y0, Y1
	VMOVDQU32 Y1, (CX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	SUBQ      $0x00000010, DX

int16NegDone1:
	CMPQ      DX, $0x00000008
	JL        int16NegDone2
	VPSUBW    (AX), X0, X1
	VMOVDQU32 X1, (CX)

int16NegDone2:
	RET

// func int32NegAvx512Asm(x []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·int32NegAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORD Z0, Z0, Z0

int32NegBlockLoop:
	CMPQ      DX, $0x000001f0
	JL        int32NegTailLoop
	VPSUBD    (AX), Z0, Z1
	VPSUBD    64(AX), Z0, Z2
	VPSUBD    128(AX), Z0, Z3
	VPSUBD    192(AX), Z0, Z4
	VPSUBD    256(AX), Z0, Z5
	VPSUBD    320(AX), Z0, Z6
	VPSUBD    384(AX), Z0, Z7
	VPSUBD    448(AX), Z0, Z8
	VPSUBD    512(AX), Z0, Z9
	VPSUBD    576(AX), Z0, Z10
	VPSUBD    640(AX), Z0, Z11
	VPSUBD    704(AX), Z0, Z12
	VPSUBD    768(AX), Z0, Z13
	VPSUBD    832(AX), Z0, Z14
	VPSUBD    896(AX), Z0, Z15
	VPSUBD    960(AX), Z0, Z16
	VPSUBD    1024(AX), Z0, Z17
	VPSUBD    1088(AX), Z0, Z18
	VPSUBD    1152(AX), Z0, Z19
	VPSUBD    1216(AX), Z0, Z20
	VPSUBD    1280(AX), Z0, Z21
	VPSUBD    1344(AX), Z0, Z22
	VPSUBD    1408(AX), Z0, Z23
	VPSUBD    1472(AX), Z0, Z24
	VPSUBD    1536(AX), Z0, Z25
	VPSUBD    1600(AX), Z0, Z26
	VPSUBD    1664(AX), Z0, Z27
	VPSUBD    1728(AX), Z0, Z28
	VPSUBD    1792(AX), Z0, Z29
	VPSUBD    1856(AX), Z0, Z30
	VPSUBD    1920(AX), Z0, Z31
	VMOVDQU32 Z1, (CX)
	VMOVDQU32 Z2, 64(CX)
	VMOVDQU32 Z3, 128(CX)
	VMOVDQU32 Z4, 192(CX)
	VMOVDQU32 Z5, 256(CX)
	VMOVDQU32 Z6, 320(CX)
	VMOVDQU32 Z7, 384(CX)
	VMOVDQU32 Z8, 448(CX)
	VMOVDQU32 Z9, 512(CX)
	VMOVDQU32 Z10, 576(CX)
	VMOVDQU32 Z11, 640(CX)
	VMOVDQU32 Z12, 704(CX)
	VMOVDQU32 Z13, 768(CX)
	VMOVDQU32 Z14, 832(CX)
	VMOVDQU32 Z15, 896(CX)
	VMOVDQU32 Z16, 960(CX)
	VMOVDQU32 Z17, 1024(CX)
	VMOVDQU32 Z18, 1088(CX)
	VMOVDQU32 Z19, 1152(CX)
	VMOVDQU32 Z20, 1216(CX)
	VMOVDQU32 Z21, 1280(CX)
	VMOVDQU32 Z22, 1344(CX)
	VMOVDQU32 Z23, 1408(CX)
	VMOVDQU32 Z24, 1472(CX)
	VMOVDQU32 Z25, 1536(CX)
	VMOVDQU32 Z26, 1600(CX)
	VMOVDQU32 Z27, 1664(CX)
	VMOVDQU32 Z28, 1728(CX)
	VMOVDQU32 Z29, 1792(CX)
	VMOVDQU32 Z30, 1856(CX)
	VMOVDQU32 Z31, 1920(CX)
	ADDQ      $0x000007c0, AX
	ADDQ      $0x000007c0, CX
	SUBQ      $0x000001f0, DX
	JMP       int32NegBlockLoop

int32NegTailLoop:
	CMPQ      DX, $0x00000010
	JL        int32NegDone
	VPSUBD    (AX), Z0, Z1
	VMOVDQU32 Z1, (CX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000010, DX
	JMP       int32NegTailLoop

int32NegDone:
	CMPQ      DX, $0x00000008
	JL        int32NegDone1
	VPSUBD    (AX), Y0, Y1
	VMOVDQU32 Y1, (CX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	SUBQ      $0x00000008, DX

int32NegDone1:
	CMPQ      DX, $0x00000004
	JL        int32NegDone2
	VPSUBD    (AX), X0, X1
	VMOVDQU32 X1, (CX)

int32NegDone2:
	RET

// func int64NegAvx512Asm(x []int64, r []int64)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·int64NegAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ   x_base+0(FP), AX
	MOVQ   r_base+24(FP), CX
	MOVQ   x_len+8(FP), DX
	VPXORD Z0, Z0, Z0

int64NegBlockLoop:
	CMPQ      DX, $0x000000f8
	JL        int64NegTailLoop
	VPSUBQ    (AX), Z0, Z1
	VPSUBQ    64(AX), Z0, Z2
	VPSUBQ    128(AX), Z0, Z3
	VPSUBQ    192(AX), Z0, Z4
	VPSUBQ    256(AX), Z0, Z5
	VPSUBQ    320(AX), Z0, Z6
	VPSUBQ    384(AX), Z0, Z7
	VPSUBQ    448(AX), Z0, Z8
	VPSUBQ    512(AX), Z0, Z9
	VPSUBQ    576(AX), Z0, Z10
	VPSUBQ    640(AX), Z0, Z11
	VPSUBQ    704(AX), Z0, Z12
	VPSUBQ    768(AX), Z0, Z13
	VPSUBQ    832(AX), Z0, Z14
	VPSUBQ    896(AX), Z0, Z15
	VPSUBQ    960(AX), Z0, Z16
	VPSUBQ    1024(AX), Z0, Z17
	VPSUBQ    1088(AX), Z0, Z18
	VPSUBQ    1152(AX), Z0, Z19
	VPSUBQ    1216(AX), Z0, Z20
	VPSUBQ    1280(AX), Z0, Z21
	VPSUBQ    1344(AX), Z0, Z22
	VPSUBQ    1408(AX), Z0, Z23
	VPSUBQ    1472(AX), Z0, Z24
	VPSUBQ    1536(AX), Z0, Z25
	VPSUBQ    1600(AX), Z0, Z26
	VPSUBQ    1664(AX), Z0, Z27
	VPSUBQ    1728(AX), Z0, Z28
	VPSUBQ    1792(AX), Z0, Z29
	VPSUBQ    1856(AX), Z0, Z30
	VPSUBQ    1920(AX), Z0, Z31
	VMOVDQU32 Z1, (CX)
	VMOVDQU32 Z2, 64(CX)
	VMOVDQU32 Z3, 128(CX)
	VMOVDQU32 Z4, 192(CX)
	VMOVDQU32 Z5, 256(CX)
	VMOVDQU32 Z6, 320(CX)
	VMOVDQU32 Z7, 384(CX)
	VMOVDQU32 Z8, 448(CX)
	VMOVDQU32 Z9, 512(CX)
	VMOVDQU32 Z10, 576(CX)
	VMOVDQU32 Z11, 640(CX)
	VMOVDQU32 Z12, 704(CX)
	VMOVDQU32 Z13, 768(CX)
	VMOVDQU32 Z14, 832(CX)
	VMOVDQU32 Z15, 896(CX)
	VMOVDQU32 Z16, 960(CX)
	VMOVDQU32 Z17, 1024(CX)
	VMOVDQU32 Z18, 1088(CX)
	VMOVDQU32 Z19, 1152(CX)
	VMOVDQU32 Z20, 1216(CX)
	VMOVDQU32 Z21, 1280(CX)
	VMOVDQU32 Z22, 1344(CX)
	VMOVDQU32 Z23, 1408(CX)
	VMOVDQU32 Z24, 1472(CX)
	VMOVDQU32 Z25, 1536(CX)
	VMOVDQU32 Z26, 1600(CX)
	VMOVDQU32 Z27, 1664(CX)
	VMOVDQU32 Z28, 1728(CX)
	VMOVDQU32 Z29, 1792(CX)
	VMOVDQU32 Z30, 1856(CX)
	VMOVDQU32 Z31, 1920(CX)
	ADDQ      $0x000007c0, AX
	ADDQ      $0x000007c0, CX
	SUBQ      $0x000000f8, DX
	JMP       int64NegBlockLoop

int64NegTailLoop:
	CMPQ      DX, $0x00000008
	JL        int64NegDone
	VPSUBQ    (AX), Z0, Z1
	VMOVDQU32 Z1, (CX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000008, DX
	JMP       int64NegTailLoop

int64NegDone:
	CMPQ      DX, $0x00000004
	JL        int64NegDone1
	VPSUBQ    (AX), Y0, Y1
	VMOVDQU32 Y1, (CX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	SUBQ      $0x00000004, DX

int64NegDone1:
	CMPQ      DX, $0x00000002
	JL        int64NegDone2
	VPSUBQ    (AX), X0, X1
	VMOVDQU32 X1, (CX)

int64NegDone2:
	RET

// func float32NegAvx512Asm(x []float32, r []float32)
// Requires: AVX512F, AVX512VL, SSE2
TEXT ·float32NegAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVL         $0x80000000, BX
	MOVD         BX, X0
	VPBROADCASTD X0, Z0

float32NegBlockLoop:
	CMPQ      DX, $0x000001f0
	JL        float32NegTailLoop
	VPXORD    (AX), Z0, Z1
	VPXORD    64(AX), Z0, Z2
	VPXORD    128(AX), Z0, Z3
	VPXORD    192(AX), Z0, Z4
	VPXORD    256(AX), Z0, Z5
	VPXORD    320(AX), Z0, Z6
	VPXORD    384(AX), Z0, Z7
	VPXORD    448(AX), Z0, Z8
	VPXORD    512(AX), Z0, Z9
	VPXORD    576(AX), Z0, Z10
	VPXORD    640(AX), Z0, Z11
	VPXORD    704(AX), Z0, Z12
	VPXORD    768(AX), Z0, Z13
	VPXORD    832(AX), Z0, Z14
	VPXORD    896(AX), Z0, Z15
	VPXORD    960(AX), Z0, Z16
	VPXORD    1024(AX), Z0, Z17
	VPXORD    1088(AX), Z0, Z18
	VPXORD    1152(AX), Z0, Z19
	VPXORD    1216(AX), Z0, Z20
	VPXORD    1280(AX), Z0, Z21
	VPXORD    1344(AX), Z0, Z22
	VPXORD    1408(AX), Z0, Z23
	VPXORD    1472(AX), Z0, Z24
	VPXORD    1536(AX), Z0, Z25
	VPXORD    1600(AX), Z0, Z26
	VPXORD    1664(AX), Z0, Z27
	VPXORD    1728(AX), Z0, Z28
	VPXORD    1792(AX), Z0, Z29
	VPXORD    1856(AX), Z0, Z30
	VPXORD    1920(AX), Z0, Z31
	VMOVDQU32 Z1, (CX)
	VMOVDQU32 Z2, 64(CX)
	VMOVDQU32 Z3, 128(CX)
	VMOVDQU32 Z4, 192(CX)
	VMOVDQU32 Z5, 256(CX)
	VMOVDQU32 Z6, 320(CX)
	VMOVDQU32 Z7, 384(CX)
	VMOVDQU32 Z8, 448(CX)
	VMOVDQU32 Z9, 512(CX)
	VMOVDQU32 Z10, 576(CX)
	VMOVDQU32 Z11, 640(CX)
	VMOVDQU32 Z12, 704(CX)
	VMOVDQU32 Z13, 768(CX)
	VMOVDQU32 Z14, 832(CX)
	VMOVDQU32 Z15, 896(CX)
	VMOVDQU32 Z16, 960(CX)
	VMOVDQU32 Z17, 1024(CX)
	VMOVDQU32 Z18, 1088(CX)
	VMOVDQU32 Z19, 1152(CX)
	VMOVDQU32 Z20, 1216(CX)
	VMOVDQU32 Z21, 1280(CX)
	VMOVDQU32 Z22, 1344(CX)
	VMOVDQU32 Z23, 1408(CX)
	VMOVDQU32 Z24, 1472(CX)
	VMOVDQU32 Z25, 1536(CX)
	VMOVDQU32 Z26, 1600(CX)
	VMOVDQU32 Z27, 1664(CX)
	VMOVDQU32 Z28, 1728(CX)
	VMOVDQU32 Z29, 1792(CX)
	VMOVDQU32 Z30, 1856(CX)
	VMOVDQU32 Z31, 1920(CX)
	ADDQ      $0x000007c0, AX
	ADDQ      $0x000007c0, CX
	SUBQ      $0x000001f0, DX
	JMP       float32NegBlockLoop

float32NegTailLoop:
	CMPQ      DX, $0x00000010
	JL        float32NegDone
	VPXORD    (AX), Z0, Z1
	VMOVDQU32 Z1, (CX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000010, DX
	JMP       float32NegTailLoop

float32NegDone:
	CMPQ      DX, $0x00000008
	JL        float32NegDone1
	VPXORD    (AX), Y0, Y1
	VMOVDQU32 Y1, (CX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	SUBQ      $0x00000008, DX

float32NegDone1:
	CMPQ      DX, $0x00000004
	JL        float32NegDone2
	VPXORD    (AX), X0, X1
	VMOVDQU32 X1, (CX)

float32NegDone2:
	RET

// func float64NegAvx512Asm(x []float64, r []float64)
// Requires: AVX512F, AVX512VL, SSE2
TEXT ·float64NegAvx512Asm(SB), NOSPLIT, $0-48
	MOVQ         x_base+0(FP), AX
	MOVQ         r_base+24(FP), CX
	MOVQ         x_len+8(FP), DX
	MOVQ         $0x8000000000000000, BX
	MOVQ         BX, X0
	VPBROADCASTQ X0, Z0

float64NegBlockLoop:
	CMPQ      DX, $0x000000f8
	JL        float64NegTailLoop
	VPXORD    (AX), Z0, Z1
	VPXORD    64(AX), Z0, Z2
	VPXORD    128(AX), Z0, Z3
	VPXORD    192(AX), Z0, Z4
	VPXORD    256(AX), Z0, Z5
	VPXORD    320(AX), Z0, Z6
	VPXORD    384(AX), Z0, Z7
	VPXORD    448(AX), Z0, Z8
	VPXORD    512(AX), Z0, Z9
	VPXORD    576(AX), Z0, Z10
	VPXORD    640(AX), Z0, Z11
	VPXORD    704(AX), Z0, Z12
	VPXORD    768(AX), Z0, Z13
	VPXORD    832(AX), Z0, Z14
	VPXORD    896(AX), Z0, Z15
	VPXORD    960(AX), Z0, Z16
	VPXORD    1024(AX), Z0, Z17
	VPXORD    1088(AX), Z0, Z18
	VPXORD    1152(AX), Z0, Z19
	VPXORD    1216(AX), Z0, Z20
	VPXORD    1280(AX), Z0, Z21
	VPXORD    1344(AX), Z0, Z22
	VPXORD    1408(AX), Z0, Z23
	VPXORD    1472(AX), Z0, Z24
	VPXORD    1536(AX), Z0, Z25
	VPXORD    1600(AX), Z0, Z26
	VPXORD    1664(AX), Z0, Z27
	VPXORD    1728(AX), Z0, Z28
	VPXORD    1792(AX), Z0, Z29
	VPXORD    1856(AX), Z0, Z30
	VPXORD    1920(AX), Z0, Z31
	VMOVDQU32 Z1, (CX)
	VMOVDQU32 Z2, 64(CX)
	VMOVDQU32 Z3, 128(CX)
	VMOVDQU32 Z4, 192(CX)
	VMOVDQU32 Z5, 256(CX)
	VMOVDQU32 Z6, 320(CX)
	VMOVDQU32 Z7, 384(CX)
	VMOVDQU32 Z8, 448(CX)
	VMOVDQU32 Z9, 512(CX)
	VMOVDQU32 Z10, 576(CX)
	VMOVDQU32 Z11, 640(CX)
	VMOVDQU32 Z12, 704(CX)
	VMOVDQU32 Z13, 768(CX)
	VMOVDQU32 Z14, 832(CX)
	VMOVDQU32 Z15, 896(CX)
	VMOVDQU32 Z16, 960(CX)
	VMOVDQU32 Z17, 1024(CX)
	VMOVDQU32 Z18, 1088(CX)
	VMOVDQU32 Z19, 1152(CX)
	VMOVDQU32 Z20, 1216(CX)
	VMOVDQU32 Z21, 1280(CX)
	VMOVDQU32 Z22, 1344(CX)
	VMOVDQU32 Z23, 1408(CX)
	VMOVDQU32 Z24, 1472(CX)
	VMOVDQU32 Z25, 1536(CX)
	VMOVDQU32 Z26, 1600(CX)
	VMOVDQU32 Z27, 1664(CX)
	VMOVDQU32 Z28, 1728(CX)
	VMOVDQU32 Z29, 1792(CX)
	VMOVDQU32 Z30, 1856(CX)
	VMOVDQU32 Z31, 1920(CX)
	ADDQ      $0x000007c0, AX
	ADDQ      $0x000007c0, CX
	SUBQ      $0x000000f8, DX
	JMP       float64NegBlockLoop

float64NegTailLoop:
	CMPQ      DX, $0x00000008
	JL        float64NegDone
	VPXORD    (AX), Z0, Z1
	VMOVDQU32 Z1, (CX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000008, DX
	JMP       float64NegTailLoop

float64NegDone:
	CMPQ      DX, $0x00000004
	JL        float64NegDone1
	VPXORD    (AX), Y0, Y1
	VMOVDQU32 Y1, (CX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	SUBQ      $0x00000004, DX

float64NegDone1:
	CMPQ      DX, $0x00000002
	JL        float64NegDone2
	VPXORD    (AX), X0, X1
	VMOVDQU32 X1, (CX)

float64NegDone2:
	RET
