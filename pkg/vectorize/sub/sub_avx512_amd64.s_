// Code generated by command: go run avx512.go -out avx512.s -stubs avx512_stubs.go. DO NOT EDIT.

#include "textflag.h"

// func int8SubAvx512Asm(x []int8, y []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·int8SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int8SubBlockLoop:
	CMPQ      BX, $0x00000800
	JL        int8SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBB    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBB    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBB    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBB    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBB    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBB    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBB    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBB    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBB    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBB    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBB    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBB    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBB    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBB    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBB    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBB    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBB    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBB    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBB    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBB    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBB    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBB    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBB    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBB    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBB    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBB    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBB    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBB    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBB    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBB    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBB    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000800, BX
	JMP       int8SubBlockLoop

int8SubTailLoop:
	CMPQ      BX, $0x00000040
	JL        int8SubDone
	VMOVDQU32 (AX), Z0
	VPSUBB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       int8SubTailLoop

int8SubDone:
	CMPQ      BX, $0x00000020
	JL        int8SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBB    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

int8SubDone1:
	CMPQ      BX, $0x00000010
	JL        int8SubDone2
	VMOVDQU32 (AX), X0
	VPSUBB    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int8SubDone2:
	RET

// func int8SubScalarAvx512Asm(x int8, y []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·int8SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVBLSX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTB X0, Z0

int8SubScalarBlockLoop:
	CMPQ      BX, $0x000007c0
	JL        int8SubScalarTailLoop
	VPSUBB    (CX), Z0, Z1
	VPSUBB    64(CX), Z0, Z2
	VPSUBB    128(CX), Z0, Z3
	VPSUBB    192(CX), Z0, Z4
	VPSUBB    256(CX), Z0, Z5
	VPSUBB    320(CX), Z0, Z6
	VPSUBB    384(CX), Z0, Z7
	VPSUBB    448(CX), Z0, Z8
	VPSUBB    512(CX), Z0, Z9
	VPSUBB    576(CX), Z0, Z10
	VPSUBB    640(CX), Z0, Z11
	VPSUBB    704(CX), Z0, Z12
	VPSUBB    768(CX), Z0, Z13
	VPSUBB    832(CX), Z0, Z14
	VPSUBB    896(CX), Z0, Z15
	VPSUBB    960(CX), Z0, Z16
	VPSUBB    1024(CX), Z0, Z17
	VPSUBB    1088(CX), Z0, Z18
	VPSUBB    1152(CX), Z0, Z19
	VPSUBB    1216(CX), Z0, Z20
	VPSUBB    1280(CX), Z0, Z21
	VPSUBB    1344(CX), Z0, Z22
	VPSUBB    1408(CX), Z0, Z23
	VPSUBB    1472(CX), Z0, Z24
	VPSUBB    1536(CX), Z0, Z25
	VPSUBB    1600(CX), Z0, Z26
	VPSUBB    1664(CX), Z0, Z27
	VPSUBB    1728(CX), Z0, Z28
	VPSUBB    1792(CX), Z0, Z29
	VPSUBB    1856(CX), Z0, Z30
	VPSUBB    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000007c0, BX
	JMP       int8SubScalarBlockLoop

int8SubScalarTailLoop:
	CMPQ      BX, $0x00000040
	JL        int8SubScalarDone
	VPSUBB    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       int8SubScalarTailLoop

int8SubScalarDone:
	CMPQ      BX, $0x00000020
	JL        int8SubScalarDone1
	VPSUBB    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

int8SubScalarDone1:
	CMPQ      BX, $0x00000010
	JL        int8SubScalarDone2
	VPSUBB    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int8SubScalarDone2:
	RET

// func int8SubByScalarAvx512Asm(x int8, y []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·int8SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVBLSX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTB X0, Z0

int8SubByScalarBlockLoop:
	CMPQ      BX, $0x000007c0
	JL        int8SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBB    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBB    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBB    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBB    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBB    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBB    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBB    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBB    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBB    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBB    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBB    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBB    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBB    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBB    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBB    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBB    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBB    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBB    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBB    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBB    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBB    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBB    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBB    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBB    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBB    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBB    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBB    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBB    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBB    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBB    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBB    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000007c0, BX
	JMP       int8SubByScalarBlockLoop

int8SubByScalarTailLoop:
	CMPQ      BX, $0x00000040
	JL        int8SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBB    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       int8SubByScalarTailLoop

int8SubByScalarDone:
	CMPQ      BX, $0x00000020
	JL        int8SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBB    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

int8SubByScalarDone1:
	CMPQ      BX, $0x00000010
	JL        int8SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBB    X0, X1, X1
	VMOVDQU32 X1, (DX)

int8SubByScalarDone2:
	RET

// func int16SubAvx512Asm(x []int16, y []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·int16SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int16SubBlockLoop:
	CMPQ      BX, $0x00000400
	JL        int16SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBW    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBW    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBW    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBW    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBW    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBW    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBW    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBW    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBW    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBW    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBW    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBW    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBW    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBW    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBW    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBW    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBW    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBW    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBW    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBW    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBW    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBW    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBW    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBW    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBW    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBW    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBW    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBW    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBW    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBW    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBW    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000400, BX
	JMP       int16SubBlockLoop

int16SubTailLoop:
	CMPQ      BX, $0x00000020
	JL        int16SubDone
	VMOVDQU32 (AX), Z0
	VPSUBW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       int16SubTailLoop

int16SubDone:
	CMPQ      BX, $0x00000010
	JL        int16SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBW    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

int16SubDone1:
	CMPQ      BX, $0x00000008
	JL        int16SubDone2
	VMOVDQU32 (AX), X0
	VPSUBW    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int16SubDone2:
	RET

// func int16SubScalarAvx512Asm(x int16, y []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·int16SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVWLSX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTW X0, Z0

int16SubScalarBlockLoop:
	CMPQ      BX, $0x000003e0
	JL        int16SubScalarTailLoop
	VPSUBW    (CX), Z0, Z1
	VPSUBW    64(CX), Z0, Z2
	VPSUBW    128(CX), Z0, Z3
	VPSUBW    192(CX), Z0, Z4
	VPSUBW    256(CX), Z0, Z5
	VPSUBW    320(CX), Z0, Z6
	VPSUBW    384(CX), Z0, Z7
	VPSUBW    448(CX), Z0, Z8
	VPSUBW    512(CX), Z0, Z9
	VPSUBW    576(CX), Z0, Z10
	VPSUBW    640(CX), Z0, Z11
	VPSUBW    704(CX), Z0, Z12
	VPSUBW    768(CX), Z0, Z13
	VPSUBW    832(CX), Z0, Z14
	VPSUBW    896(CX), Z0, Z15
	VPSUBW    960(CX), Z0, Z16
	VPSUBW    1024(CX), Z0, Z17
	VPSUBW    1088(CX), Z0, Z18
	VPSUBW    1152(CX), Z0, Z19
	VPSUBW    1216(CX), Z0, Z20
	VPSUBW    1280(CX), Z0, Z21
	VPSUBW    1344(CX), Z0, Z22
	VPSUBW    1408(CX), Z0, Z23
	VPSUBW    1472(CX), Z0, Z24
	VPSUBW    1536(CX), Z0, Z25
	VPSUBW    1600(CX), Z0, Z26
	VPSUBW    1664(CX), Z0, Z27
	VPSUBW    1728(CX), Z0, Z28
	VPSUBW    1792(CX), Z0, Z29
	VPSUBW    1856(CX), Z0, Z30
	VPSUBW    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000003e0, BX
	JMP       int16SubScalarBlockLoop

int16SubScalarTailLoop:
	CMPQ      BX, $0x00000020
	JL        int16SubScalarDone
	VPSUBW    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       int16SubScalarTailLoop

int16SubScalarDone:
	CMPQ      BX, $0x00000010
	JL        int16SubScalarDone1
	VPSUBW    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

int16SubScalarDone1:
	CMPQ      BX, $0x00000008
	JL        int16SubScalarDone2
	VPSUBW    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int16SubScalarDone2:
	RET

// func int16SubByScalarAvx512Asm(x int16, y []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·int16SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVWLSX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTW X0, Z0

int16SubByScalarBlockLoop:
	CMPQ      BX, $0x000003e0
	JL        int16SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBW    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBW    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBW    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBW    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBW    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBW    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBW    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBW    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBW    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBW    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBW    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBW    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBW    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBW    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBW    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBW    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBW    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBW    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBW    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBW    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBW    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBW    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBW    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBW    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBW    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBW    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBW    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBW    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBW    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBW    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBW    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000003e0, BX
	JMP       int16SubByScalarBlockLoop

int16SubByScalarTailLoop:
	CMPQ      BX, $0x00000020
	JL        int16SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBW    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       int16SubByScalarTailLoop

int16SubByScalarDone:
	CMPQ      BX, $0x00000010
	JL        int16SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBW    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

int16SubByScalarDone1:
	CMPQ      BX, $0x00000008
	JL        int16SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBW    X0, X1, X1
	VMOVDQU32 X1, (DX)

int16SubByScalarDone2:
	RET

// func int32SubAvx512Asm(x []int32, y []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·int32SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int32SubBlockLoop:
	CMPQ      BX, $0x00000200
	JL        int32SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBD    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBD    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBD    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBD    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBD    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBD    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBD    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBD    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBD    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBD    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBD    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBD    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBD    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBD    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBD    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBD    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBD    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBD    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBD    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBD    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBD    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBD    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBD    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBD    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBD    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBD    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBD    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBD    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBD    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBD    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBD    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000200, BX
	JMP       int32SubBlockLoop

int32SubTailLoop:
	CMPQ      BX, $0x00000010
	JL        int32SubDone
	VMOVDQU32 (AX), Z0
	VPSUBD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       int32SubTailLoop

int32SubDone:
	CMPQ      BX, $0x00000008
	JL        int32SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBD    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

int32SubDone1:
	CMPQ      BX, $0x00000004
	JL        int32SubDone2
	VMOVDQU32 (AX), X0
	VPSUBD    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int32SubDone2:
	RET

// func int32SubScalarAvx512Asm(x int32, y []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·int32SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVL         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTD X0, Z0

int32SubScalarBlockLoop:
	CMPQ      BX, $0x000001f0
	JL        int32SubScalarTailLoop
	VPSUBD    (CX), Z0, Z1
	VPSUBD    64(CX), Z0, Z2
	VPSUBD    128(CX), Z0, Z3
	VPSUBD    192(CX), Z0, Z4
	VPSUBD    256(CX), Z0, Z5
	VPSUBD    320(CX), Z0, Z6
	VPSUBD    384(CX), Z0, Z7
	VPSUBD    448(CX), Z0, Z8
	VPSUBD    512(CX), Z0, Z9
	VPSUBD    576(CX), Z0, Z10
	VPSUBD    640(CX), Z0, Z11
	VPSUBD    704(CX), Z0, Z12
	VPSUBD    768(CX), Z0, Z13
	VPSUBD    832(CX), Z0, Z14
	VPSUBD    896(CX), Z0, Z15
	VPSUBD    960(CX), Z0, Z16
	VPSUBD    1024(CX), Z0, Z17
	VPSUBD    1088(CX), Z0, Z18
	VPSUBD    1152(CX), Z0, Z19
	VPSUBD    1216(CX), Z0, Z20
	VPSUBD    1280(CX), Z0, Z21
	VPSUBD    1344(CX), Z0, Z22
	VPSUBD    1408(CX), Z0, Z23
	VPSUBD    1472(CX), Z0, Z24
	VPSUBD    1536(CX), Z0, Z25
	VPSUBD    1600(CX), Z0, Z26
	VPSUBD    1664(CX), Z0, Z27
	VPSUBD    1728(CX), Z0, Z28
	VPSUBD    1792(CX), Z0, Z29
	VPSUBD    1856(CX), Z0, Z30
	VPSUBD    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000001f0, BX
	JMP       int32SubScalarBlockLoop

int32SubScalarTailLoop:
	CMPQ      BX, $0x00000010
	JL        int32SubScalarDone
	VPSUBD    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       int32SubScalarTailLoop

int32SubScalarDone:
	CMPQ      BX, $0x00000008
	JL        int32SubScalarDone1
	VPSUBD    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

int32SubScalarDone1:
	CMPQ      BX, $0x00000004
	JL        int32SubScalarDone2
	VPSUBD    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int32SubScalarDone2:
	RET

// func int32SubByScalarAvx512Asm(x int32, y []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·int32SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVL         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTD X0, Z0

int32SubByScalarBlockLoop:
	CMPQ      BX, $0x000001f0
	JL        int32SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBD    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBD    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBD    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBD    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBD    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBD    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBD    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBD    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBD    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBD    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBD    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBD    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBD    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBD    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBD    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBD    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBD    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBD    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBD    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBD    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBD    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBD    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBD    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBD    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBD    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBD    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBD    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBD    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBD    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBD    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBD    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000001f0, BX
	JMP       int32SubByScalarBlockLoop

int32SubByScalarTailLoop:
	CMPQ      BX, $0x00000010
	JL        int32SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBD    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       int32SubByScalarTailLoop

int32SubByScalarDone:
	CMPQ      BX, $0x00000008
	JL        int32SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBD    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

int32SubByScalarDone1:
	CMPQ      BX, $0x00000004
	JL        int32SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBD    X0, X1, X1
	VMOVDQU32 X1, (DX)

int32SubByScalarDone2:
	RET

// func int64SubAvx512Asm(x []int64, y []int64, r []int64)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·int64SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int64SubBlockLoop:
	CMPQ      BX, $0x00000100
	JL        int64SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBQ    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBQ    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBQ    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBQ    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBQ    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBQ    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBQ    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBQ    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBQ    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBQ    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBQ    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBQ    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBQ    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBQ    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBQ    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBQ    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBQ    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBQ    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBQ    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBQ    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBQ    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBQ    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBQ    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBQ    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBQ    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBQ    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBQ    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBQ    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBQ    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBQ    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBQ    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000100, BX
	JMP       int64SubBlockLoop

int64SubTailLoop:
	CMPQ      BX, $0x00000008
	JL        int64SubDone
	VMOVDQU32 (AX), Z0
	VPSUBQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       int64SubTailLoop

int64SubDone:
	CMPQ      BX, $0x00000004
	JL        int64SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBQ    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

int64SubDone1:
	CMPQ      BX, $0x00000002
	JL        int64SubDone2
	VMOVDQU32 (AX), X0
	VPSUBQ    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int64SubDone2:
	RET

// func int64SubScalarAvx512Asm(x int64, y []int64, r []int64)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·int64SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVQ         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVQ         AX, X0
	VPBROADCASTQ X0, Z0

int64SubScalarBlockLoop:
	CMPQ      BX, $0x000000f8
	JL        int64SubScalarTailLoop
	VPSUBQ    (CX), Z0, Z1
	VPSUBQ    64(CX), Z0, Z2
	VPSUBQ    128(CX), Z0, Z3
	VPSUBQ    192(CX), Z0, Z4
	VPSUBQ    256(CX), Z0, Z5
	VPSUBQ    320(CX), Z0, Z6
	VPSUBQ    384(CX), Z0, Z7
	VPSUBQ    448(CX), Z0, Z8
	VPSUBQ    512(CX), Z0, Z9
	VPSUBQ    576(CX), Z0, Z10
	VPSUBQ    640(CX), Z0, Z11
	VPSUBQ    704(CX), Z0, Z12
	VPSUBQ    768(CX), Z0, Z13
	VPSUBQ    832(CX), Z0, Z14
	VPSUBQ    896(CX), Z0, Z15
	VPSUBQ    960(CX), Z0, Z16
	VPSUBQ    1024(CX), Z0, Z17
	VPSUBQ    1088(CX), Z0, Z18
	VPSUBQ    1152(CX), Z0, Z19
	VPSUBQ    1216(CX), Z0, Z20
	VPSUBQ    1280(CX), Z0, Z21
	VPSUBQ    1344(CX), Z0, Z22
	VPSUBQ    1408(CX), Z0, Z23
	VPSUBQ    1472(CX), Z0, Z24
	VPSUBQ    1536(CX), Z0, Z25
	VPSUBQ    1600(CX), Z0, Z26
	VPSUBQ    1664(CX), Z0, Z27
	VPSUBQ    1728(CX), Z0, Z28
	VPSUBQ    1792(CX), Z0, Z29
	VPSUBQ    1856(CX), Z0, Z30
	VPSUBQ    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000000f8, BX
	JMP       int64SubScalarBlockLoop

int64SubScalarTailLoop:
	CMPQ      BX, $0x00000008
	JL        int64SubScalarDone
	VPSUBQ    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       int64SubScalarTailLoop

int64SubScalarDone:
	CMPQ      BX, $0x00000004
	JL        int64SubScalarDone1
	VPSUBQ    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

int64SubScalarDone1:
	CMPQ      BX, $0x00000002
	JL        int64SubScalarDone2
	VPSUBQ    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int64SubScalarDone2:
	RET

// func int64SubByScalarAvx512Asm(x int64, y []int64, r []int64)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·int64SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVQ         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVQ         AX, X0
	VPBROADCASTQ X0, Z0

int64SubByScalarBlockLoop:
	CMPQ      BX, $0x000000f8
	JL        int64SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBQ    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBQ    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBQ    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBQ    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBQ    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBQ    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBQ    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBQ    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBQ    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBQ    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBQ    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBQ    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBQ    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBQ    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBQ    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBQ    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBQ    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBQ    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBQ    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBQ    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBQ    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBQ    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBQ    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBQ    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBQ    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBQ    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBQ    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBQ    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBQ    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBQ    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBQ    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000000f8, BX
	JMP       int64SubByScalarBlockLoop

int64SubByScalarTailLoop:
	CMPQ      BX, $0x00000008
	JL        int64SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBQ    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       int64SubByScalarTailLoop

int64SubByScalarDone:
	CMPQ      BX, $0x00000004
	JL        int64SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBQ    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

int64SubByScalarDone1:
	CMPQ      BX, $0x00000002
	JL        int64SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBQ    X0, X1, X1
	VMOVDQU32 X1, (DX)

int64SubByScalarDone2:
	RET

// func uint8SubAvx512Asm(x []uint8, y []uint8, r []uint8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·uint8SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint8SubBlockLoop:
	CMPQ      BX, $0x00000800
	JL        uint8SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBB    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBB    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBB    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBB    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBB    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBB    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBB    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBB    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBB    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBB    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBB    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBB    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBB    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBB    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBB    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBB    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBB    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBB    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBB    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBB    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBB    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBB    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBB    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBB    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBB    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBB    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBB    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBB    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBB    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBB    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBB    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000800, BX
	JMP       uint8SubBlockLoop

uint8SubTailLoop:
	CMPQ      BX, $0x00000040
	JL        uint8SubDone
	VMOVDQU32 (AX), Z0
	VPSUBB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       uint8SubTailLoop

uint8SubDone:
	CMPQ      BX, $0x00000020
	JL        uint8SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBB    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

uint8SubDone1:
	CMPQ      BX, $0x00000010
	JL        uint8SubDone2
	VMOVDQU32 (AX), X0
	VPSUBB    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint8SubDone2:
	RET

// func uint8SubScalarAvx512Asm(x uint8, y []uint8, r []uint8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·uint8SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVBLZX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTB X0, Z0

uint8SubScalarBlockLoop:
	CMPQ      BX, $0x000007c0
	JL        uint8SubScalarTailLoop
	VPSUBB    (CX), Z0, Z1
	VPSUBB    64(CX), Z0, Z2
	VPSUBB    128(CX), Z0, Z3
	VPSUBB    192(CX), Z0, Z4
	VPSUBB    256(CX), Z0, Z5
	VPSUBB    320(CX), Z0, Z6
	VPSUBB    384(CX), Z0, Z7
	VPSUBB    448(CX), Z0, Z8
	VPSUBB    512(CX), Z0, Z9
	VPSUBB    576(CX), Z0, Z10
	VPSUBB    640(CX), Z0, Z11
	VPSUBB    704(CX), Z0, Z12
	VPSUBB    768(CX), Z0, Z13
	VPSUBB    832(CX), Z0, Z14
	VPSUBB    896(CX), Z0, Z15
	VPSUBB    960(CX), Z0, Z16
	VPSUBB    1024(CX), Z0, Z17
	VPSUBB    1088(CX), Z0, Z18
	VPSUBB    1152(CX), Z0, Z19
	VPSUBB    1216(CX), Z0, Z20
	VPSUBB    1280(CX), Z0, Z21
	VPSUBB    1344(CX), Z0, Z22
	VPSUBB    1408(CX), Z0, Z23
	VPSUBB    1472(CX), Z0, Z24
	VPSUBB    1536(CX), Z0, Z25
	VPSUBB    1600(CX), Z0, Z26
	VPSUBB    1664(CX), Z0, Z27
	VPSUBB    1728(CX), Z0, Z28
	VPSUBB    1792(CX), Z0, Z29
	VPSUBB    1856(CX), Z0, Z30
	VPSUBB    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000007c0, BX
	JMP       uint8SubScalarBlockLoop

uint8SubScalarTailLoop:
	CMPQ      BX, $0x00000040
	JL        uint8SubScalarDone
	VPSUBB    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       uint8SubScalarTailLoop

uint8SubScalarDone:
	CMPQ      BX, $0x00000020
	JL        uint8SubScalarDone1
	VPSUBB    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

uint8SubScalarDone1:
	CMPQ      BX, $0x00000010
	JL        uint8SubScalarDone2
	VPSUBB    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint8SubScalarDone2:
	RET

// func uint8SubByScalarAvx512Asm(x uint8, y []uint8, r []uint8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·uint8SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVBLZX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTB X0, Z0

uint8SubByScalarBlockLoop:
	CMPQ      BX, $0x000007c0
	JL        uint8SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBB    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBB    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBB    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBB    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBB    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBB    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBB    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBB    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBB    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBB    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBB    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBB    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBB    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBB    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBB    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBB    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBB    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBB    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBB    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBB    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBB    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBB    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBB    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBB    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBB    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBB    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBB    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBB    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBB    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBB    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBB    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000007c0, BX
	JMP       uint8SubByScalarBlockLoop

uint8SubByScalarTailLoop:
	CMPQ      BX, $0x00000040
	JL        uint8SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBB    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       uint8SubByScalarTailLoop

uint8SubByScalarDone:
	CMPQ      BX, $0x00000020
	JL        uint8SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBB    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

uint8SubByScalarDone1:
	CMPQ      BX, $0x00000010
	JL        uint8SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBB    X0, X1, X1
	VMOVDQU32 X1, (DX)

uint8SubByScalarDone2:
	RET

// func uint16SubAvx512Asm(x []uint16, y []uint16, r []uint16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·uint16SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint16SubBlockLoop:
	CMPQ      BX, $0x00000400
	JL        uint16SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBW    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBW    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBW    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBW    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBW    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBW    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBW    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBW    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBW    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBW    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBW    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBW    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBW    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBW    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBW    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBW    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBW    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBW    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBW    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBW    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBW    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBW    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBW    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBW    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBW    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBW    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBW    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBW    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBW    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBW    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBW    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000400, BX
	JMP       uint16SubBlockLoop

uint16SubTailLoop:
	CMPQ      BX, $0x00000020
	JL        uint16SubDone
	VMOVDQU32 (AX), Z0
	VPSUBW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       uint16SubTailLoop

uint16SubDone:
	CMPQ      BX, $0x00000010
	JL        uint16SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBW    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

uint16SubDone1:
	CMPQ      BX, $0x00000008
	JL        uint16SubDone2
	VMOVDQU32 (AX), X0
	VPSUBW    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint16SubDone2:
	RET

// func uint16SubScalarAvx512Asm(x uint16, y []uint16, r []uint16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·uint16SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVWLZX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTW X0, Z0

uint16SubScalarBlockLoop:
	CMPQ      BX, $0x000003e0
	JL        uint16SubScalarTailLoop
	VPSUBW    (CX), Z0, Z1
	VPSUBW    64(CX), Z0, Z2
	VPSUBW    128(CX), Z0, Z3
	VPSUBW    192(CX), Z0, Z4
	VPSUBW    256(CX), Z0, Z5
	VPSUBW    320(CX), Z0, Z6
	VPSUBW    384(CX), Z0, Z7
	VPSUBW    448(CX), Z0, Z8
	VPSUBW    512(CX), Z0, Z9
	VPSUBW    576(CX), Z0, Z10
	VPSUBW    640(CX), Z0, Z11
	VPSUBW    704(CX), Z0, Z12
	VPSUBW    768(CX), Z0, Z13
	VPSUBW    832(CX), Z0, Z14
	VPSUBW    896(CX), Z0, Z15
	VPSUBW    960(CX), Z0, Z16
	VPSUBW    1024(CX), Z0, Z17
	VPSUBW    1088(CX), Z0, Z18
	VPSUBW    1152(CX), Z0, Z19
	VPSUBW    1216(CX), Z0, Z20
	VPSUBW    1280(CX), Z0, Z21
	VPSUBW    1344(CX), Z0, Z22
	VPSUBW    1408(CX), Z0, Z23
	VPSUBW    1472(CX), Z0, Z24
	VPSUBW    1536(CX), Z0, Z25
	VPSUBW    1600(CX), Z0, Z26
	VPSUBW    1664(CX), Z0, Z27
	VPSUBW    1728(CX), Z0, Z28
	VPSUBW    1792(CX), Z0, Z29
	VPSUBW    1856(CX), Z0, Z30
	VPSUBW    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000003e0, BX
	JMP       uint16SubScalarBlockLoop

uint16SubScalarTailLoop:
	CMPQ      BX, $0x00000020
	JL        uint16SubScalarDone
	VPSUBW    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       uint16SubScalarTailLoop

uint16SubScalarDone:
	CMPQ      BX, $0x00000010
	JL        uint16SubScalarDone1
	VPSUBW    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

uint16SubScalarDone1:
	CMPQ      BX, $0x00000008
	JL        uint16SubScalarDone2
	VPSUBW    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint16SubScalarDone2:
	RET

// func uint16SubByScalarAvx512Asm(x uint16, y []uint16, r []uint16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·uint16SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVWLZX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTW X0, Z0

uint16SubByScalarBlockLoop:
	CMPQ      BX, $0x000003e0
	JL        uint16SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBW    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBW    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBW    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBW    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBW    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBW    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBW    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBW    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBW    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBW    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBW    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBW    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBW    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBW    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBW    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBW    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBW    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBW    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBW    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBW    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBW    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBW    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBW    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBW    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBW    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBW    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBW    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBW    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBW    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBW    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBW    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000003e0, BX
	JMP       uint16SubByScalarBlockLoop

uint16SubByScalarTailLoop:
	CMPQ      BX, $0x00000020
	JL        uint16SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBW    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       uint16SubByScalarTailLoop

uint16SubByScalarDone:
	CMPQ      BX, $0x00000010
	JL        uint16SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBW    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

uint16SubByScalarDone1:
	CMPQ      BX, $0x00000008
	JL        uint16SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBW    X0, X1, X1
	VMOVDQU32 X1, (DX)

uint16SubByScalarDone2:
	RET

// func uint32SubAvx512Asm(x []uint32, y []uint32, r []uint32)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·uint32SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint32SubBlockLoop:
	CMPQ      BX, $0x00000200
	JL        uint32SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBD    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBD    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBD    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBD    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBD    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBD    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBD    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBD    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBD    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBD    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBD    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBD    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBD    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBD    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBD    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBD    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBD    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBD    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBD    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBD    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBD    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBD    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBD    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBD    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBD    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBD    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBD    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBD    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBD    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBD    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBD    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000200, BX
	JMP       uint32SubBlockLoop

uint32SubTailLoop:
	CMPQ      BX, $0x00000010
	JL        uint32SubDone
	VMOVDQU32 (AX), Z0
	VPSUBD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       uint32SubTailLoop

uint32SubDone:
	CMPQ      BX, $0x00000008
	JL        uint32SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBD    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

uint32SubDone1:
	CMPQ      BX, $0x00000004
	JL        uint32SubDone2
	VMOVDQU32 (AX), X0
	VPSUBD    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint32SubDone2:
	RET

// func uint32SubScalarAvx512Asm(x uint32, y []uint32, r []uint32)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·uint32SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVL         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTD X0, Z0

uint32SubScalarBlockLoop:
	CMPQ      BX, $0x000001f0
	JL        uint32SubScalarTailLoop
	VPSUBD    (CX), Z0, Z1
	VPSUBD    64(CX), Z0, Z2
	VPSUBD    128(CX), Z0, Z3
	VPSUBD    192(CX), Z0, Z4
	VPSUBD    256(CX), Z0, Z5
	VPSUBD    320(CX), Z0, Z6
	VPSUBD    384(CX), Z0, Z7
	VPSUBD    448(CX), Z0, Z8
	VPSUBD    512(CX), Z0, Z9
	VPSUBD    576(CX), Z0, Z10
	VPSUBD    640(CX), Z0, Z11
	VPSUBD    704(CX), Z0, Z12
	VPSUBD    768(CX), Z0, Z13
	VPSUBD    832(CX), Z0, Z14
	VPSUBD    896(CX), Z0, Z15
	VPSUBD    960(CX), Z0, Z16
	VPSUBD    1024(CX), Z0, Z17
	VPSUBD    1088(CX), Z0, Z18
	VPSUBD    1152(CX), Z0, Z19
	VPSUBD    1216(CX), Z0, Z20
	VPSUBD    1280(CX), Z0, Z21
	VPSUBD    1344(CX), Z0, Z22
	VPSUBD    1408(CX), Z0, Z23
	VPSUBD    1472(CX), Z0, Z24
	VPSUBD    1536(CX), Z0, Z25
	VPSUBD    1600(CX), Z0, Z26
	VPSUBD    1664(CX), Z0, Z27
	VPSUBD    1728(CX), Z0, Z28
	VPSUBD    1792(CX), Z0, Z29
	VPSUBD    1856(CX), Z0, Z30
	VPSUBD    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000001f0, BX
	JMP       uint32SubScalarBlockLoop

uint32SubScalarTailLoop:
	CMPQ      BX, $0x00000010
	JL        uint32SubScalarDone
	VPSUBD    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       uint32SubScalarTailLoop

uint32SubScalarDone:
	CMPQ      BX, $0x00000008
	JL        uint32SubScalarDone1
	VPSUBD    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

uint32SubScalarDone1:
	CMPQ      BX, $0x00000004
	JL        uint32SubScalarDone2
	VPSUBD    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint32SubScalarDone2:
	RET

// func uint32SubByScalarAvx512Asm(x uint32, y []uint32, r []uint32)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·uint32SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVL         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTD X0, Z0

uint32SubByScalarBlockLoop:
	CMPQ      BX, $0x000001f0
	JL        uint32SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBD    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBD    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBD    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBD    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBD    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBD    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBD    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBD    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBD    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBD    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBD    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBD    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBD    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBD    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBD    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBD    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBD    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBD    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBD    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBD    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBD    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBD    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBD    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBD    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBD    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBD    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBD    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBD    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBD    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBD    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBD    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000001f0, BX
	JMP       uint32SubByScalarBlockLoop

uint32SubByScalarTailLoop:
	CMPQ      BX, $0x00000010
	JL        uint32SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBD    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       uint32SubByScalarTailLoop

uint32SubByScalarDone:
	CMPQ      BX, $0x00000008
	JL        uint32SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBD    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

uint32SubByScalarDone1:
	CMPQ      BX, $0x00000004
	JL        uint32SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBD    X0, X1, X1
	VMOVDQU32 X1, (DX)

uint32SubByScalarDone2:
	RET

// func uint64SubAvx512Asm(x []uint64, y []uint64, r []uint64)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·uint64SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint64SubBlockLoop:
	CMPQ      BX, $0x00000100
	JL        uint64SubTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPSUBQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPSUBQ    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPSUBQ    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPSUBQ    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPSUBQ    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPSUBQ    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPSUBQ    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPSUBQ    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPSUBQ    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPSUBQ    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPSUBQ    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPSUBQ    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPSUBQ    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPSUBQ    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPSUBQ    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPSUBQ    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPSUBQ    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPSUBQ    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPSUBQ    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPSUBQ    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPSUBQ    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPSUBQ    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPSUBQ    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPSUBQ    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPSUBQ    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPSUBQ    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPSUBQ    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPSUBQ    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPSUBQ    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPSUBQ    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPSUBQ    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPSUBQ    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000100, BX
	JMP       uint64SubBlockLoop

uint64SubTailLoop:
	CMPQ      BX, $0x00000008
	JL        uint64SubDone
	VMOVDQU32 (AX), Z0
	VPSUBQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       uint64SubTailLoop

uint64SubDone:
	CMPQ      BX, $0x00000004
	JL        uint64SubDone1
	VMOVDQU32 (AX), Y0
	VPSUBQ    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

uint64SubDone1:
	CMPQ      BX, $0x00000002
	JL        uint64SubDone2
	VMOVDQU32 (AX), X0
	VPSUBQ    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint64SubDone2:
	RET

// func uint64SubScalarAvx512Asm(x uint64, y []uint64, r []uint64)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·uint64SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVQ         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVQ         AX, X0
	VPBROADCASTQ X0, Z0

uint64SubScalarBlockLoop:
	CMPQ      BX, $0x000000f8
	JL        uint64SubScalarTailLoop
	VPSUBQ    (CX), Z0, Z1
	VPSUBQ    64(CX), Z0, Z2
	VPSUBQ    128(CX), Z0, Z3
	VPSUBQ    192(CX), Z0, Z4
	VPSUBQ    256(CX), Z0, Z5
	VPSUBQ    320(CX), Z0, Z6
	VPSUBQ    384(CX), Z0, Z7
	VPSUBQ    448(CX), Z0, Z8
	VPSUBQ    512(CX), Z0, Z9
	VPSUBQ    576(CX), Z0, Z10
	VPSUBQ    640(CX), Z0, Z11
	VPSUBQ    704(CX), Z0, Z12
	VPSUBQ    768(CX), Z0, Z13
	VPSUBQ    832(CX), Z0, Z14
	VPSUBQ    896(CX), Z0, Z15
	VPSUBQ    960(CX), Z0, Z16
	VPSUBQ    1024(CX), Z0, Z17
	VPSUBQ    1088(CX), Z0, Z18
	VPSUBQ    1152(CX), Z0, Z19
	VPSUBQ    1216(CX), Z0, Z20
	VPSUBQ    1280(CX), Z0, Z21
	VPSUBQ    1344(CX), Z0, Z22
	VPSUBQ    1408(CX), Z0, Z23
	VPSUBQ    1472(CX), Z0, Z24
	VPSUBQ    1536(CX), Z0, Z25
	VPSUBQ    1600(CX), Z0, Z26
	VPSUBQ    1664(CX), Z0, Z27
	VPSUBQ    1728(CX), Z0, Z28
	VPSUBQ    1792(CX), Z0, Z29
	VPSUBQ    1856(CX), Z0, Z30
	VPSUBQ    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000000f8, BX
	JMP       uint64SubScalarBlockLoop

uint64SubScalarTailLoop:
	CMPQ      BX, $0x00000008
	JL        uint64SubScalarDone
	VPSUBQ    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       uint64SubScalarTailLoop

uint64SubScalarDone:
	CMPQ      BX, $0x00000004
	JL        uint64SubScalarDone1
	VPSUBQ    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

uint64SubScalarDone1:
	CMPQ      BX, $0x00000002
	JL        uint64SubScalarDone2
	VPSUBQ    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint64SubScalarDone2:
	RET

// func uint64SubByScalarAvx512Asm(x uint64, y []uint64, r []uint64)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·uint64SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVQ         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVQ         AX, X0
	VPBROADCASTQ X0, Z0

uint64SubByScalarBlockLoop:
	CMPQ      BX, $0x000000f8
	JL        uint64SubByScalarTailLoop
	VMOVDQU32 (CX), Z1
	VMOVDQU32 64(CX), Z2
	VMOVDQU32 128(CX), Z3
	VMOVDQU32 192(CX), Z4
	VMOVDQU32 256(CX), Z5
	VMOVDQU32 320(CX), Z6
	VMOVDQU32 384(CX), Z7
	VMOVDQU32 448(CX), Z8
	VMOVDQU32 512(CX), Z9
	VMOVDQU32 576(CX), Z10
	VMOVDQU32 640(CX), Z11
	VMOVDQU32 704(CX), Z12
	VMOVDQU32 768(CX), Z13
	VMOVDQU32 832(CX), Z14
	VMOVDQU32 896(CX), Z15
	VMOVDQU32 960(CX), Z16
	VMOVDQU32 1024(CX), Z17
	VMOVDQU32 1088(CX), Z18
	VMOVDQU32 1152(CX), Z19
	VMOVDQU32 1216(CX), Z20
	VMOVDQU32 1280(CX), Z21
	VMOVDQU32 1344(CX), Z22
	VMOVDQU32 1408(CX), Z23
	VMOVDQU32 1472(CX), Z24
	VMOVDQU32 1536(CX), Z25
	VMOVDQU32 1600(CX), Z26
	VMOVDQU32 1664(CX), Z27
	VMOVDQU32 1728(CX), Z28
	VMOVDQU32 1792(CX), Z29
	VMOVDQU32 1856(CX), Z30
	VMOVDQU32 1920(CX), Z31
	VPSUBQ    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	VPSUBQ    Z0, Z2, Z2
	VMOVDQU32 Z2, 64(DX)
	VPSUBQ    Z0, Z3, Z3
	VMOVDQU32 Z3, 128(DX)
	VPSUBQ    Z0, Z4, Z4
	VMOVDQU32 Z4, 192(DX)
	VPSUBQ    Z0, Z5, Z5
	VMOVDQU32 Z5, 256(DX)
	VPSUBQ    Z0, Z6, Z6
	VMOVDQU32 Z6, 320(DX)
	VPSUBQ    Z0, Z7, Z7
	VMOVDQU32 Z7, 384(DX)
	VPSUBQ    Z0, Z8, Z8
	VMOVDQU32 Z8, 448(DX)
	VPSUBQ    Z0, Z9, Z9
	VMOVDQU32 Z9, 512(DX)
	VPSUBQ    Z0, Z10, Z10
	VMOVDQU32 Z10, 576(DX)
	VPSUBQ    Z0, Z11, Z11
	VMOVDQU32 Z11, 640(DX)
	VPSUBQ    Z0, Z12, Z12
	VMOVDQU32 Z12, 704(DX)
	VPSUBQ    Z0, Z13, Z13
	VMOVDQU32 Z13, 768(DX)
	VPSUBQ    Z0, Z14, Z14
	VMOVDQU32 Z14, 832(DX)
	VPSUBQ    Z0, Z15, Z15
	VMOVDQU32 Z15, 896(DX)
	VPSUBQ    Z0, Z16, Z16
	VMOVDQU32 Z16, 960(DX)
	VPSUBQ    Z0, Z17, Z17
	VMOVDQU32 Z17, 1024(DX)
	VPSUBQ    Z0, Z18, Z18
	VMOVDQU32 Z18, 1088(DX)
	VPSUBQ    Z0, Z19, Z19
	VMOVDQU32 Z19, 1152(DX)
	VPSUBQ    Z0, Z20, Z20
	VMOVDQU32 Z20, 1216(DX)
	VPSUBQ    Z0, Z21, Z21
	VMOVDQU32 Z21, 1280(DX)
	VPSUBQ    Z0, Z22, Z22
	VMOVDQU32 Z22, 1344(DX)
	VPSUBQ    Z0, Z23, Z23
	VMOVDQU32 Z23, 1408(DX)
	VPSUBQ    Z0, Z24, Z24
	VMOVDQU32 Z24, 1472(DX)
	VPSUBQ    Z0, Z25, Z25
	VMOVDQU32 Z25, 1536(DX)
	VPSUBQ    Z0, Z26, Z26
	VMOVDQU32 Z26, 1600(DX)
	VPSUBQ    Z0, Z27, Z27
	VMOVDQU32 Z27, 1664(DX)
	VPSUBQ    Z0, Z28, Z28
	VMOVDQU32 Z28, 1728(DX)
	VPSUBQ    Z0, Z29, Z29
	VMOVDQU32 Z29, 1792(DX)
	VPSUBQ    Z0, Z30, Z30
	VMOVDQU32 Z30, 1856(DX)
	VPSUBQ    Z0, Z31, Z31
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000000f8, BX
	JMP       uint64SubByScalarBlockLoop

uint64SubByScalarTailLoop:
	CMPQ      BX, $0x00000008
	JL        uint64SubByScalarDone
	VMOVDQU32 (CX), Z1
	VPSUBQ    Z0, Z1, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       uint64SubByScalarTailLoop

uint64SubByScalarDone:
	CMPQ      BX, $0x00000004
	JL        uint64SubByScalarDone1
	VMOVDQU32 (CX), Y1
	VPSUBQ    Y0, Y1, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

uint64SubByScalarDone1:
	CMPQ      BX, $0x00000002
	JL        uint64SubByScalarDone2
	VMOVDQU32 (CX), X1
	VPSUBQ    X0, X1, X1
	VMOVDQU32 X1, (DX)

uint64SubByScalarDone2:
	RET

// func float32SubAvx512Asm(x []float32, y []float32, r []float32)
// Requires: AVX, AVX512F
TEXT ·float32SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

float32SubBlockLoop:
	CMPQ    BX, $0x00000200
	JL      float32SubTailLoop
	VMOVUPS (AX), Z0
	VMOVUPS 64(AX), Z1
	VMOVUPS 128(AX), Z2
	VMOVUPS 192(AX), Z3
	VMOVUPS 256(AX), Z4
	VMOVUPS 320(AX), Z5
	VMOVUPS 384(AX), Z6
	VMOVUPS 448(AX), Z7
	VMOVUPS 512(AX), Z8
	VMOVUPS 576(AX), Z9
	VMOVUPS 640(AX), Z10
	VMOVUPS 704(AX), Z11
	VMOVUPS 768(AX), Z12
	VMOVUPS 832(AX), Z13
	VMOVUPS 896(AX), Z14
	VMOVUPS 960(AX), Z15
	VMOVUPS 1024(AX), Z16
	VMOVUPS 1088(AX), Z17
	VMOVUPS 1152(AX), Z18
	VMOVUPS 1216(AX), Z19
	VMOVUPS 1280(AX), Z20
	VMOVUPS 1344(AX), Z21
	VMOVUPS 1408(AX), Z22
	VMOVUPS 1472(AX), Z23
	VMOVUPS 1536(AX), Z24
	VMOVUPS 1600(AX), Z25
	VMOVUPS 1664(AX), Z26
	VMOVUPS 1728(AX), Z27
	VMOVUPS 1792(AX), Z28
	VMOVUPS 1856(AX), Z29
	VMOVUPS 1920(AX), Z30
	VMOVUPS 1984(AX), Z31
	VSUBPS  (CX), Z0, Z0
	VMOVUPS Z0, (DX)
	VSUBPS  64(CX), Z1, Z1
	VMOVUPS Z1, 64(DX)
	VSUBPS  128(CX), Z2, Z2
	VMOVUPS Z2, 128(DX)
	VSUBPS  192(CX), Z3, Z3
	VMOVUPS Z3, 192(DX)
	VSUBPS  256(CX), Z4, Z4
	VMOVUPS Z4, 256(DX)
	VSUBPS  320(CX), Z5, Z5
	VMOVUPS Z5, 320(DX)
	VSUBPS  384(CX), Z6, Z6
	VMOVUPS Z6, 384(DX)
	VSUBPS  448(CX), Z7, Z7
	VMOVUPS Z7, 448(DX)
	VSUBPS  512(CX), Z8, Z8
	VMOVUPS Z8, 512(DX)
	VSUBPS  576(CX), Z9, Z9
	VMOVUPS Z9, 576(DX)
	VSUBPS  640(CX), Z10, Z10
	VMOVUPS Z10, 640(DX)
	VSUBPS  704(CX), Z11, Z11
	VMOVUPS Z11, 704(DX)
	VSUBPS  768(CX), Z12, Z12
	VMOVUPS Z12, 768(DX)
	VSUBPS  832(CX), Z13, Z13
	VMOVUPS Z13, 832(DX)
	VSUBPS  896(CX), Z14, Z14
	VMOVUPS Z14, 896(DX)
	VSUBPS  960(CX), Z15, Z15
	VMOVUPS Z15, 960(DX)
	VSUBPS  1024(CX), Z16, Z16
	VMOVUPS Z16, 1024(DX)
	VSUBPS  1088(CX), Z17, Z17
	VMOVUPS Z17, 1088(DX)
	VSUBPS  1152(CX), Z18, Z18
	VMOVUPS Z18, 1152(DX)
	VSUBPS  1216(CX), Z19, Z19
	VMOVUPS Z19, 1216(DX)
	VSUBPS  1280(CX), Z20, Z20
	VMOVUPS Z20, 1280(DX)
	VSUBPS  1344(CX), Z21, Z21
	VMOVUPS Z21, 1344(DX)
	VSUBPS  1408(CX), Z22, Z22
	VMOVUPS Z22, 1408(DX)
	VSUBPS  1472(CX), Z23, Z23
	VMOVUPS Z23, 1472(DX)
	VSUBPS  1536(CX), Z24, Z24
	VMOVUPS Z24, 1536(DX)
	VSUBPS  1600(CX), Z25, Z25
	VMOVUPS Z25, 1600(DX)
	VSUBPS  1664(CX), Z26, Z26
	VMOVUPS Z26, 1664(DX)
	VSUBPS  1728(CX), Z27, Z27
	VMOVUPS Z27, 1728(DX)
	VSUBPS  1792(CX), Z28, Z28
	VMOVUPS Z28, 1792(DX)
	VSUBPS  1856(CX), Z29, Z29
	VMOVUPS Z29, 1856(DX)
	VSUBPS  1920(CX), Z30, Z30
	VMOVUPS Z30, 1920(DX)
	VSUBPS  1984(CX), Z31, Z31
	VMOVUPS Z31, 1984(DX)
	ADDQ    $0x00000800, AX
	ADDQ    $0x00000800, CX
	ADDQ    $0x00000800, DX
	SUBQ    $0x00000200, BX
	JMP     float32SubBlockLoop

float32SubTailLoop:
	CMPQ    BX, $0x00000010
	JL      float32SubDone
	VMOVUPS (AX), Z0
	VSUBPS  (CX), Z0, Z0
	VMOVUPS Z0, (DX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	ADDQ    $0x00000040, DX
	SUBQ    $0x00000010, BX
	JMP     float32SubTailLoop

float32SubDone:
	CMPQ    BX, $0x00000008
	JL      float32SubDone1
	VMOVUPS (AX), Y0
	VSUBPS  (CX), Y0, Y0
	VMOVUPS Y0, (DX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	ADDQ    $0x00000020, DX
	SUBQ    $0x00000008, BX

float32SubDone1:
	CMPQ    BX, $0x00000004
	JL      float32SubDone2
	VMOVUPS (AX), X0
	VSUBPS  (CX), X0, X0
	VMOVUPS X0, (DX)

float32SubDone2:
	RET

// func float32SubScalarAvx512Asm(x float32, y []float32, r []float32)
// Requires: AVX, AVX512F, SSE
TEXT ·float32SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVSS        x+0(FP), X0
	MOVQ         y_base+8(FP), AX
	MOVQ         r_base+32(FP), CX
	MOVQ         y_len+16(FP), DX
	VBROADCASTSS X0, Z0

float32SubScalarBlockLoop:
	CMPQ    DX, $0x000001f0
	JL      float32SubScalarTailLoop
	VSUBPS  (AX), Z0, Z1
	VSUBPS  64(AX), Z0, Z2
	VSUBPS  128(AX), Z0, Z3
	VSUBPS  192(AX), Z0, Z4
	VSUBPS  256(AX), Z0, Z5
	VSUBPS  320(AX), Z0, Z6
	VSUBPS  384(AX), Z0, Z7
	VSUBPS  448(AX), Z0, Z8
	VSUBPS  512(AX), Z0, Z9
	VSUBPS  576(AX), Z0, Z10
	VSUBPS  640(AX), Z0, Z11
	VSUBPS  704(AX), Z0, Z12
	VSUBPS  768(AX), Z0, Z13
	VSUBPS  832(AX), Z0, Z14
	VSUBPS  896(AX), Z0, Z15
	VSUBPS  960(AX), Z0, Z16
	VSUBPS  1024(AX), Z0, Z17
	VSUBPS  1088(AX), Z0, Z18
	VSUBPS  1152(AX), Z0, Z19
	VSUBPS  1216(AX), Z0, Z20
	VSUBPS  1280(AX), Z0, Z21
	VSUBPS  1344(AX), Z0, Z22
	VSUBPS  1408(AX), Z0, Z23
	VSUBPS  1472(AX), Z0, Z24
	VSUBPS  1536(AX), Z0, Z25
	VSUBPS  1600(AX), Z0, Z26
	VSUBPS  1664(AX), Z0, Z27
	VSUBPS  1728(AX), Z0, Z28
	VSUBPS  1792(AX), Z0, Z29
	VSUBPS  1856(AX), Z0, Z30
	VSUBPS  1920(AX), Z0, Z31
	VMOVUPS Z1, (CX)
	VMOVUPS Z2, 64(CX)
	VMOVUPS Z3, 128(CX)
	VMOVUPS Z4, 192(CX)
	VMOVUPS Z5, 256(CX)
	VMOVUPS Z6, 320(CX)
	VMOVUPS Z7, 384(CX)
	VMOVUPS Z8, 448(CX)
	VMOVUPS Z9, 512(CX)
	VMOVUPS Z10, 576(CX)
	VMOVUPS Z11, 640(CX)
	VMOVUPS Z12, 704(CX)
	VMOVUPS Z13, 768(CX)
	VMOVUPS Z14, 832(CX)
	VMOVUPS Z15, 896(CX)
	VMOVUPS Z16, 960(CX)
	VMOVUPS Z17, 1024(CX)
	VMOVUPS Z18, 1088(CX)
	VMOVUPS Z19, 1152(CX)
	VMOVUPS Z20, 1216(CX)
	VMOVUPS Z21, 1280(CX)
	VMOVUPS Z22, 1344(CX)
	VMOVUPS Z23, 1408(CX)
	VMOVUPS Z24, 1472(CX)
	VMOVUPS Z25, 1536(CX)
	VMOVUPS Z26, 1600(CX)
	VMOVUPS Z27, 1664(CX)
	VMOVUPS Z28, 1728(CX)
	VMOVUPS Z29, 1792(CX)
	VMOVUPS Z30, 1856(CX)
	VMOVUPS Z31, 1920(CX)
	ADDQ    $0x000007c0, AX
	ADDQ    $0x000007c0, CX
	SUBQ    $0x000001f0, DX
	JMP     float32SubScalarBlockLoop

float32SubScalarTailLoop:
	CMPQ    DX, $0x00000010
	JL      float32SubScalarDone
	VSUBPS  (AX), Z0, Z1
	VMOVUPS Z1, (CX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	SUBQ    $0x00000010, DX
	JMP     float32SubScalarTailLoop

float32SubScalarDone:
	CMPQ    DX, $0x00000008
	JL      float32SubScalarDone1
	VSUBPS  (AX), Y0, Y1
	VMOVUPS Y1, (CX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	SUBQ    $0x00000008, DX

float32SubScalarDone1:
	CMPQ    DX, $0x00000004
	JL      float32SubScalarDone2
	VSUBPS  (AX), X0, X1
	VMOVUPS X1, (CX)

float32SubScalarDone2:
	RET

// func float32SubByScalarAvx512Asm(x float32, y []float32, r []float32)
// Requires: AVX, AVX512F, SSE
TEXT ·float32SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVSS        x+0(FP), X0
	MOVQ         y_base+8(FP), AX
	MOVQ         r_base+32(FP), CX
	MOVQ         y_len+16(FP), DX
	VBROADCASTSS X0, Z0

float32SubByScalarBlockLoop:
	CMPQ    DX, $0x000001f0
	JL      float32SubByScalarTailLoop
	VMOVUPS (AX), Z1
	VMOVUPS 64(AX), Z2
	VMOVUPS 128(AX), Z3
	VMOVUPS 192(AX), Z4
	VMOVUPS 256(AX), Z5
	VMOVUPS 320(AX), Z6
	VMOVUPS 384(AX), Z7
	VMOVUPS 448(AX), Z8
	VMOVUPS 512(AX), Z9
	VMOVUPS 576(AX), Z10
	VMOVUPS 640(AX), Z11
	VMOVUPS 704(AX), Z12
	VMOVUPS 768(AX), Z13
	VMOVUPS 832(AX), Z14
	VMOVUPS 896(AX), Z15
	VMOVUPS 960(AX), Z16
	VMOVUPS 1024(AX), Z17
	VMOVUPS 1088(AX), Z18
	VMOVUPS 1152(AX), Z19
	VMOVUPS 1216(AX), Z20
	VMOVUPS 1280(AX), Z21
	VMOVUPS 1344(AX), Z22
	VMOVUPS 1408(AX), Z23
	VMOVUPS 1472(AX), Z24
	VMOVUPS 1536(AX), Z25
	VMOVUPS 1600(AX), Z26
	VMOVUPS 1664(AX), Z27
	VMOVUPS 1728(AX), Z28
	VMOVUPS 1792(AX), Z29
	VMOVUPS 1856(AX), Z30
	VMOVUPS 1920(AX), Z31
	VSUBPS  Z0, Z1, Z1
	VMOVUPS Z1, (CX)
	VSUBPS  Z0, Z2, Z2
	VMOVUPS Z2, 64(CX)
	VSUBPS  Z0, Z3, Z3
	VMOVUPS Z3, 128(CX)
	VSUBPS  Z0, Z4, Z4
	VMOVUPS Z4, 192(CX)
	VSUBPS  Z0, Z5, Z5
	VMOVUPS Z5, 256(CX)
	VSUBPS  Z0, Z6, Z6
	VMOVUPS Z6, 320(CX)
	VSUBPS  Z0, Z7, Z7
	VMOVUPS Z7, 384(CX)
	VSUBPS  Z0, Z8, Z8
	VMOVUPS Z8, 448(CX)
	VSUBPS  Z0, Z9, Z9
	VMOVUPS Z9, 512(CX)
	VSUBPS  Z0, Z10, Z10
	VMOVUPS Z10, 576(CX)
	VSUBPS  Z0, Z11, Z11
	VMOVUPS Z11, 640(CX)
	VSUBPS  Z0, Z12, Z12
	VMOVUPS Z12, 704(CX)
	VSUBPS  Z0, Z13, Z13
	VMOVUPS Z13, 768(CX)
	VSUBPS  Z0, Z14, Z14
	VMOVUPS Z14, 832(CX)
	VSUBPS  Z0, Z15, Z15
	VMOVUPS Z15, 896(CX)
	VSUBPS  Z0, Z16, Z16
	VMOVUPS Z16, 960(CX)
	VSUBPS  Z0, Z17, Z17
	VMOVUPS Z17, 1024(CX)
	VSUBPS  Z0, Z18, Z18
	VMOVUPS Z18, 1088(CX)
	VSUBPS  Z0, Z19, Z19
	VMOVUPS Z19, 1152(CX)
	VSUBPS  Z0, Z20, Z20
	VMOVUPS Z20, 1216(CX)
	VSUBPS  Z0, Z21, Z21
	VMOVUPS Z21, 1280(CX)
	VSUBPS  Z0, Z22, Z22
	VMOVUPS Z22, 1344(CX)
	VSUBPS  Z0, Z23, Z23
	VMOVUPS Z23, 1408(CX)
	VSUBPS  Z0, Z24, Z24
	VMOVUPS Z24, 1472(CX)
	VSUBPS  Z0, Z25, Z25
	VMOVUPS Z25, 1536(CX)
	VSUBPS  Z0, Z26, Z26
	VMOVUPS Z26, 1600(CX)
	VSUBPS  Z0, Z27, Z27
	VMOVUPS Z27, 1664(CX)
	VSUBPS  Z0, Z28, Z28
	VMOVUPS Z28, 1728(CX)
	VSUBPS  Z0, Z29, Z29
	VMOVUPS Z29, 1792(CX)
	VSUBPS  Z0, Z30, Z30
	VMOVUPS Z30, 1856(CX)
	VSUBPS  Z0, Z31, Z31
	VMOVUPS Z31, 1920(CX)
	ADDQ    $0x000007c0, AX
	ADDQ    $0x000007c0, CX
	SUBQ    $0x000001f0, DX
	JMP     float32SubByScalarBlockLoop

float32SubByScalarTailLoop:
	CMPQ    DX, $0x00000010
	JL      float32SubByScalarDone
	VMOVUPS (AX), Z1
	VSUBPS  Z0, Z1, Z1
	VMOVUPS Z1, (CX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	SUBQ    $0x00000010, DX
	JMP     float32SubByScalarTailLoop

float32SubByScalarDone:
	CMPQ    DX, $0x00000008
	JL      float32SubByScalarDone1
	VMOVUPS (AX), Y1
	VSUBPS  Y0, Y1, Y1
	VMOVUPS Y1, (CX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	SUBQ    $0x00000008, DX

float32SubByScalarDone1:
	CMPQ    DX, $0x00000004
	JL      float32SubByScalarDone2
	VMOVUPS (AX), X1
	VSUBPS  X0, X1, X1
	VMOVUPS X1, (CX)

float32SubByScalarDone2:
	RET

// func float64SubAvx512Asm(x []float64, y []float64, r []float64)
// Requires: AVX, AVX512F
TEXT ·float64SubAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

float64SubBlockLoop:
	CMPQ    BX, $0x00000100
	JL      float64SubTailLoop
	VMOVUPD (AX), Z0
	VMOVUPD 64(AX), Z1
	VMOVUPD 128(AX), Z2
	VMOVUPD 192(AX), Z3
	VMOVUPD 256(AX), Z4
	VMOVUPD 320(AX), Z5
	VMOVUPD 384(AX), Z6
	VMOVUPD 448(AX), Z7
	VMOVUPD 512(AX), Z8
	VMOVUPD 576(AX), Z9
	VMOVUPD 640(AX), Z10
	VMOVUPD 704(AX), Z11
	VMOVUPD 768(AX), Z12
	VMOVUPD 832(AX), Z13
	VMOVUPD 896(AX), Z14
	VMOVUPD 960(AX), Z15
	VMOVUPD 1024(AX), Z16
	VMOVUPD 1088(AX), Z17
	VMOVUPD 1152(AX), Z18
	VMOVUPD 1216(AX), Z19
	VMOVUPD 1280(AX), Z20
	VMOVUPD 1344(AX), Z21
	VMOVUPD 1408(AX), Z22
	VMOVUPD 1472(AX), Z23
	VMOVUPD 1536(AX), Z24
	VMOVUPD 1600(AX), Z25
	VMOVUPD 1664(AX), Z26
	VMOVUPD 1728(AX), Z27
	VMOVUPD 1792(AX), Z28
	VMOVUPD 1856(AX), Z29
	VMOVUPD 1920(AX), Z30
	VMOVUPD 1984(AX), Z31
	VSUBPD  (CX), Z0, Z0
	VMOVUPD Z0, (DX)
	VSUBPD  64(CX), Z1, Z1
	VMOVUPD Z1, 64(DX)
	VSUBPD  128(CX), Z2, Z2
	VMOVUPD Z2, 128(DX)
	VSUBPD  192(CX), Z3, Z3
	VMOVUPD Z3, 192(DX)
	VSUBPD  256(CX), Z4, Z4
	VMOVUPD Z4, 256(DX)
	VSUBPD  320(CX), Z5, Z5
	VMOVUPD Z5, 320(DX)
	VSUBPD  384(CX), Z6, Z6
	VMOVUPD Z6, 384(DX)
	VSUBPD  448(CX), Z7, Z7
	VMOVUPD Z7, 448(DX)
	VSUBPD  512(CX), Z8, Z8
	VMOVUPD Z8, 512(DX)
	VSUBPD  576(CX), Z9, Z9
	VMOVUPD Z9, 576(DX)
	VSUBPD  640(CX), Z10, Z10
	VMOVUPD Z10, 640(DX)
	VSUBPD  704(CX), Z11, Z11
	VMOVUPD Z11, 704(DX)
	VSUBPD  768(CX), Z12, Z12
	VMOVUPD Z12, 768(DX)
	VSUBPD  832(CX), Z13, Z13
	VMOVUPD Z13, 832(DX)
	VSUBPD  896(CX), Z14, Z14
	VMOVUPD Z14, 896(DX)
	VSUBPD  960(CX), Z15, Z15
	VMOVUPD Z15, 960(DX)
	VSUBPD  1024(CX), Z16, Z16
	VMOVUPD Z16, 1024(DX)
	VSUBPD  1088(CX), Z17, Z17
	VMOVUPD Z17, 1088(DX)
	VSUBPD  1152(CX), Z18, Z18
	VMOVUPD Z18, 1152(DX)
	VSUBPD  1216(CX), Z19, Z19
	VMOVUPD Z19, 1216(DX)
	VSUBPD  1280(CX), Z20, Z20
	VMOVUPD Z20, 1280(DX)
	VSUBPD  1344(CX), Z21, Z21
	VMOVUPD Z21, 1344(DX)
	VSUBPD  1408(CX), Z22, Z22
	VMOVUPD Z22, 1408(DX)
	VSUBPD  1472(CX), Z23, Z23
	VMOVUPD Z23, 1472(DX)
	VSUBPD  1536(CX), Z24, Z24
	VMOVUPD Z24, 1536(DX)
	VSUBPD  1600(CX), Z25, Z25
	VMOVUPD Z25, 1600(DX)
	VSUBPD  1664(CX), Z26, Z26
	VMOVUPD Z26, 1664(DX)
	VSUBPD  1728(CX), Z27, Z27
	VMOVUPD Z27, 1728(DX)
	VSUBPD  1792(CX), Z28, Z28
	VMOVUPD Z28, 1792(DX)
	VSUBPD  1856(CX), Z29, Z29
	VMOVUPD Z29, 1856(DX)
	VSUBPD  1920(CX), Z30, Z30
	VMOVUPD Z30, 1920(DX)
	VSUBPD  1984(CX), Z31, Z31
	VMOVUPD Z31, 1984(DX)
	ADDQ    $0x00000800, AX
	ADDQ    $0x00000800, CX
	ADDQ    $0x00000800, DX
	SUBQ    $0x00000100, BX
	JMP     float64SubBlockLoop

float64SubTailLoop:
	CMPQ    BX, $0x00000008
	JL      float64SubDone
	VMOVUPD (AX), Z0
	VSUBPD  (CX), Z0, Z0
	VMOVUPD Z0, (DX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	ADDQ    $0x00000040, DX
	SUBQ    $0x00000008, BX
	JMP     float64SubTailLoop

float64SubDone:
	CMPQ    BX, $0x00000004
	JL      float64SubDone1
	VMOVUPD (AX), Y0
	VSUBPD  (CX), Y0, Y0
	VMOVUPD Y0, (DX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	ADDQ    $0x00000020, DX
	SUBQ    $0x00000004, BX

float64SubDone1:
	CMPQ    BX, $0x00000002
	JL      float64SubDone2
	VMOVUPD (AX), X0
	VSUBPD  (CX), X0, X0
	VMOVUPD X0, (DX)

float64SubDone2:
	RET

// func float64SubScalarAvx512Asm(x float64, y []float64, r []float64)
// Requires: AVX, AVX512F, SSE2
TEXT ·float64SubScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVSD        x+0(FP), X0
	MOVQ         y_base+8(FP), AX
	MOVQ         r_base+32(FP), CX
	MOVQ         y_len+16(FP), DX
	VBROADCASTSD X0, Z0

float64SubScalarBlockLoop:
	CMPQ    DX, $0x000000f8
	JL      float64SubScalarTailLoop
	VSUBPD  (AX), Z0, Z1
	VSUBPD  64(AX), Z0, Z2
	VSUBPD  128(AX), Z0, Z3
	VSUBPD  192(AX), Z0, Z4
	VSUBPD  256(AX), Z0, Z5
	VSUBPD  320(AX), Z0, Z6
	VSUBPD  384(AX), Z0, Z7
	VSUBPD  448(AX), Z0, Z8
	VSUBPD  512(AX), Z0, Z9
	VSUBPD  576(AX), Z0, Z10
	VSUBPD  640(AX), Z0, Z11
	VSUBPD  704(AX), Z0, Z12
	VSUBPD  768(AX), Z0, Z13
	VSUBPD  832(AX), Z0, Z14
	VSUBPD  896(AX), Z0, Z15
	VSUBPD  960(AX), Z0, Z16
	VSUBPD  1024(AX), Z0, Z17
	VSUBPD  1088(AX), Z0, Z18
	VSUBPD  1152(AX), Z0, Z19
	VSUBPD  1216(AX), Z0, Z20
	VSUBPD  1280(AX), Z0, Z21
	VSUBPD  1344(AX), Z0, Z22
	VSUBPD  1408(AX), Z0, Z23
	VSUBPD  1472(AX), Z0, Z24
	VSUBPD  1536(AX), Z0, Z25
	VSUBPD  1600(AX), Z0, Z26
	VSUBPD  1664(AX), Z0, Z27
	VSUBPD  1728(AX), Z0, Z28
	VSUBPD  1792(AX), Z0, Z29
	VSUBPD  1856(AX), Z0, Z30
	VSUBPD  1920(AX), Z0, Z31
	VMOVUPD Z1, (CX)
	VMOVUPD Z2, 64(CX)
	VMOVUPD Z3, 128(CX)
	VMOVUPD Z4, 192(CX)
	VMOVUPD Z5, 256(CX)
	VMOVUPD Z6, 320(CX)
	VMOVUPD Z7, 384(CX)
	VMOVUPD Z8, 448(CX)
	VMOVUPD Z9, 512(CX)
	VMOVUPD Z10, 576(CX)
	VMOVUPD Z11, 640(CX)
	VMOVUPD Z12, 704(CX)
	VMOVUPD Z13, 768(CX)
	VMOVUPD Z14, 832(CX)
	VMOVUPD Z15, 896(CX)
	VMOVUPD Z16, 960(CX)
	VMOVUPD Z17, 1024(CX)
	VMOVUPD Z18, 1088(CX)
	VMOVUPD Z19, 1152(CX)
	VMOVUPD Z20, 1216(CX)
	VMOVUPD Z21, 1280(CX)
	VMOVUPD Z22, 1344(CX)
	VMOVUPD Z23, 1408(CX)
	VMOVUPD Z24, 1472(CX)
	VMOVUPD Z25, 1536(CX)
	VMOVUPD Z26, 1600(CX)
	VMOVUPD Z27, 1664(CX)
	VMOVUPD Z28, 1728(CX)
	VMOVUPD Z29, 1792(CX)
	VMOVUPD Z30, 1856(CX)
	VMOVUPD Z31, 1920(CX)
	ADDQ    $0x000007c0, AX
	ADDQ    $0x000007c0, CX
	SUBQ    $0x000000f8, DX
	JMP     float64SubScalarBlockLoop

float64SubScalarTailLoop:
	CMPQ    DX, $0x00000008
	JL      float64SubScalarDone
	VSUBPD  (AX), Z0, Z1
	VMOVUPD Z1, (CX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	SUBQ    $0x00000008, DX
	JMP     float64SubScalarTailLoop

float64SubScalarDone:
	CMPQ    DX, $0x00000004
	JL      float64SubScalarDone1
	VSUBPD  (AX), Y0, Y1
	VMOVUPD Y1, (CX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	SUBQ    $0x00000004, DX

float64SubScalarDone1:
	CMPQ    DX, $0x00000002
	JL      float64SubScalarDone2
	VSUBPD  (AX), X0, X1
	VMOVUPD X1, (CX)

float64SubScalarDone2:
	RET

// func float64SubByScalarAvx512Asm(x float64, y []float64, r []float64)
// Requires: AVX, AVX512F, SSE2
TEXT ·float64SubByScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVSD        x+0(FP), X0
	MOVQ         y_base+8(FP), AX
	MOVQ         r_base+32(FP), CX
	MOVQ         y_len+16(FP), DX
	VBROADCASTSD X0, Z0

float64SubByScalarBlockLoop:
	CMPQ    DX, $0x000000f8
	JL      float64SubByScalarTailLoop
	VMOVUPD (AX), Z1
	VMOVUPD 64(AX), Z2
	VMOVUPD 128(AX), Z3
	VMOVUPD 192(AX), Z4
	VMOVUPD 256(AX), Z5
	VMOVUPD 320(AX), Z6
	VMOVUPD 384(AX), Z7
	VMOVUPD 448(AX), Z8
	VMOVUPD 512(AX), Z9
	VMOVUPD 576(AX), Z10
	VMOVUPD 640(AX), Z11
	VMOVUPD 704(AX), Z12
	VMOVUPD 768(AX), Z13
	VMOVUPD 832(AX), Z14
	VMOVUPD 896(AX), Z15
	VMOVUPD 960(AX), Z16
	VMOVUPD 1024(AX), Z17
	VMOVUPD 1088(AX), Z18
	VMOVUPD 1152(AX), Z19
	VMOVUPD 1216(AX), Z20
	VMOVUPD 1280(AX), Z21
	VMOVUPD 1344(AX), Z22
	VMOVUPD 1408(AX), Z23
	VMOVUPD 1472(AX), Z24
	VMOVUPD 1536(AX), Z25
	VMOVUPD 1600(AX), Z26
	VMOVUPD 1664(AX), Z27
	VMOVUPD 1728(AX), Z28
	VMOVUPD 1792(AX), Z29
	VMOVUPD 1856(AX), Z30
	VMOVUPD 1920(AX), Z31
	VSUBPD  Z0, Z1, Z1
	VMOVUPD Z1, (CX)
	VSUBPD  Z0, Z2, Z2
	VMOVUPD Z2, 64(CX)
	VSUBPD  Z0, Z3, Z3
	VMOVUPD Z3, 128(CX)
	VSUBPD  Z0, Z4, Z4
	VMOVUPD Z4, 192(CX)
	VSUBPD  Z0, Z5, Z5
	VMOVUPD Z5, 256(CX)
	VSUBPD  Z0, Z6, Z6
	VMOVUPD Z6, 320(CX)
	VSUBPD  Z0, Z7, Z7
	VMOVUPD Z7, 384(CX)
	VSUBPD  Z0, Z8, Z8
	VMOVUPD Z8, 448(CX)
	VSUBPD  Z0, Z9, Z9
	VMOVUPD Z9, 512(CX)
	VSUBPD  Z0, Z10, Z10
	VMOVUPD Z10, 576(CX)
	VSUBPD  Z0, Z11, Z11
	VMOVUPD Z11, 640(CX)
	VSUBPD  Z0, Z12, Z12
	VMOVUPD Z12, 704(CX)
	VSUBPD  Z0, Z13, Z13
	VMOVUPD Z13, 768(CX)
	VSUBPD  Z0, Z14, Z14
	VMOVUPD Z14, 832(CX)
	VSUBPD  Z0, Z15, Z15
	VMOVUPD Z15, 896(CX)
	VSUBPD  Z0, Z16, Z16
	VMOVUPD Z16, 960(CX)
	VSUBPD  Z0, Z17, Z17
	VMOVUPD Z17, 1024(CX)
	VSUBPD  Z0, Z18, Z18
	VMOVUPD Z18, 1088(CX)
	VSUBPD  Z0, Z19, Z19
	VMOVUPD Z19, 1152(CX)
	VSUBPD  Z0, Z20, Z20
	VMOVUPD Z20, 1216(CX)
	VSUBPD  Z0, Z21, Z21
	VMOVUPD Z21, 1280(CX)
	VSUBPD  Z0, Z22, Z22
	VMOVUPD Z22, 1344(CX)
	VSUBPD  Z0, Z23, Z23
	VMOVUPD Z23, 1408(CX)
	VSUBPD  Z0, Z24, Z24
	VMOVUPD Z24, 1472(CX)
	VSUBPD  Z0, Z25, Z25
	VMOVUPD Z25, 1536(CX)
	VSUBPD  Z0, Z26, Z26
	VMOVUPD Z26, 1600(CX)
	VSUBPD  Z0, Z27, Z27
	VMOVUPD Z27, 1664(CX)
	VSUBPD  Z0, Z28, Z28
	VMOVUPD Z28, 1728(CX)
	VSUBPD  Z0, Z29, Z29
	VMOVUPD Z29, 1792(CX)
	VSUBPD  Z0, Z30, Z30
	VMOVUPD Z30, 1856(CX)
	VSUBPD  Z0, Z31, Z31
	VMOVUPD Z31, 1920(CX)
	ADDQ    $0x000007c0, AX
	ADDQ    $0x000007c0, CX
	SUBQ    $0x000000f8, DX
	JMP     float64SubByScalarBlockLoop

float64SubByScalarTailLoop:
	CMPQ    DX, $0x00000008
	JL      float64SubByScalarDone
	VMOVUPD (AX), Z1
	VSUBPD  Z0, Z1, Z1
	VMOVUPD Z1, (CX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	SUBQ    $0x00000008, DX
	JMP     float64SubByScalarTailLoop

float64SubByScalarDone:
	CMPQ    DX, $0x00000004
	JL      float64SubByScalarDone1
	VMOVUPD (AX), Y1
	VSUBPD  Y0, Y1, Y1
	VMOVUPD Y1, (CX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	SUBQ    $0x00000004, DX

float64SubByScalarDone1:
	CMPQ    DX, $0x00000002
	JL      float64SubByScalarDone2
	VMOVUPD (AX), X1
	VSUBPD  X0, X1, X1
	VMOVUPD X1, (CX)

float64SubByScalarDone2:
	RET
