// Code generated by command: go run avx512.go -out avx512.s -stubs avx512_stubs.go. DO NOT EDIT.
// +build amd64

#include "textflag.h"

// func int8AddAvx512Asm(x []int8, y []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·int8AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int8AddBlockLoop:
	CMPQ      BX, $0x00000800
	JL        int8AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDB    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDB    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDB    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDB    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDB    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDB    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDB    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDB    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDB    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDB    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDB    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDB    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDB    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDB    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDB    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDB    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDB    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDB    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDB    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDB    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDB    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDB    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDB    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDB    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDB    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDB    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDB    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDB    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDB    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDB    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDB    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000800, BX
	JMP       int8AddBlockLoop

int8AddTailLoop:
	CMPQ      BX, $0x00000040
	JL        int8AddDone
	VMOVDQU32 (AX), Z0
	VPADDB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       int8AddTailLoop

int8AddDone:
	CMPQ      BX, $0x00000020
	JL        int8AddDone1
	VMOVDQU32 (AX), Y0
	VPADDB    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

int8AddDone1:
	CMPQ      BX, $0x00000010
	JL        int8AddDone2
	VMOVDQU32 (AX), X0
	VPADDB    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int8AddDone2:
	RET

// func int8AddScalarAvx512Asm(x int8, y []int8, r []int8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·int8AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVBLSX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTB X0, Z0

int8AddScalarBlockLoop:
	CMPQ      BX, $0x000007c0
	JL        int8AddScalarTailLoop
	VPADDB    (CX), Z0, Z1
	VPADDB    64(CX), Z0, Z2
	VPADDB    128(CX), Z0, Z3
	VPADDB    192(CX), Z0, Z4
	VPADDB    256(CX), Z0, Z5
	VPADDB    320(CX), Z0, Z6
	VPADDB    384(CX), Z0, Z7
	VPADDB    448(CX), Z0, Z8
	VPADDB    512(CX), Z0, Z9
	VPADDB    576(CX), Z0, Z10
	VPADDB    640(CX), Z0, Z11
	VPADDB    704(CX), Z0, Z12
	VPADDB    768(CX), Z0, Z13
	VPADDB    832(CX), Z0, Z14
	VPADDB    896(CX), Z0, Z15
	VPADDB    960(CX), Z0, Z16
	VPADDB    1024(CX), Z0, Z17
	VPADDB    1088(CX), Z0, Z18
	VPADDB    1152(CX), Z0, Z19
	VPADDB    1216(CX), Z0, Z20
	VPADDB    1280(CX), Z0, Z21
	VPADDB    1344(CX), Z0, Z22
	VPADDB    1408(CX), Z0, Z23
	VPADDB    1472(CX), Z0, Z24
	VPADDB    1536(CX), Z0, Z25
	VPADDB    1600(CX), Z0, Z26
	VPADDB    1664(CX), Z0, Z27
	VPADDB    1728(CX), Z0, Z28
	VPADDB    1792(CX), Z0, Z29
	VPADDB    1856(CX), Z0, Z30
	VPADDB    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000007c0, BX
	JMP       int8AddScalarBlockLoop

int8AddScalarTailLoop:
	CMPQ      BX, $0x00000040
	JL        int8AddScalarDone
	VPADDB    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       int8AddScalarTailLoop

int8AddScalarDone:
	CMPQ      BX, $0x00000020
	JL        int8AddScalarDone1
	VPADDB    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

int8AddScalarDone1:
	CMPQ      BX, $0x00000010
	JL        int8AddScalarDone2
	VPADDB    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int8AddScalarDone2:
	RET

// func int16AddAvx512Asm(x []int16, y []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·int16AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int16AddBlockLoop:
	CMPQ      BX, $0x00000400
	JL        int16AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDW    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDW    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDW    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDW    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDW    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDW    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDW    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDW    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDW    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDW    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDW    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDW    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDW    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDW    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDW    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDW    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDW    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDW    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDW    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDW    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDW    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDW    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDW    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDW    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDW    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDW    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDW    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDW    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDW    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDW    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDW    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000400, BX
	JMP       int16AddBlockLoop

int16AddTailLoop:
	CMPQ      BX, $0x00000020
	JL        int16AddDone
	VMOVDQU32 (AX), Z0
	VPADDW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       int16AddTailLoop

int16AddDone:
	CMPQ      BX, $0x00000010
	JL        int16AddDone1
	VMOVDQU32 (AX), Y0
	VPADDW    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

int16AddDone1:
	CMPQ      BX, $0x00000008
	JL        int16AddDone2
	VMOVDQU32 (AX), X0
	VPADDW    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int16AddDone2:
	RET

// func int16AddScalarAvx512Asm(x int16, y []int16, r []int16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·int16AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVWLSX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTW X0, Z0

int16AddScalarBlockLoop:
	CMPQ      BX, $0x000003e0
	JL        int16AddScalarTailLoop
	VPADDW    (CX), Z0, Z1
	VPADDW    64(CX), Z0, Z2
	VPADDW    128(CX), Z0, Z3
	VPADDW    192(CX), Z0, Z4
	VPADDW    256(CX), Z0, Z5
	VPADDW    320(CX), Z0, Z6
	VPADDW    384(CX), Z0, Z7
	VPADDW    448(CX), Z0, Z8
	VPADDW    512(CX), Z0, Z9
	VPADDW    576(CX), Z0, Z10
	VPADDW    640(CX), Z0, Z11
	VPADDW    704(CX), Z0, Z12
	VPADDW    768(CX), Z0, Z13
	VPADDW    832(CX), Z0, Z14
	VPADDW    896(CX), Z0, Z15
	VPADDW    960(CX), Z0, Z16
	VPADDW    1024(CX), Z0, Z17
	VPADDW    1088(CX), Z0, Z18
	VPADDW    1152(CX), Z0, Z19
	VPADDW    1216(CX), Z0, Z20
	VPADDW    1280(CX), Z0, Z21
	VPADDW    1344(CX), Z0, Z22
	VPADDW    1408(CX), Z0, Z23
	VPADDW    1472(CX), Z0, Z24
	VPADDW    1536(CX), Z0, Z25
	VPADDW    1600(CX), Z0, Z26
	VPADDW    1664(CX), Z0, Z27
	VPADDW    1728(CX), Z0, Z28
	VPADDW    1792(CX), Z0, Z29
	VPADDW    1856(CX), Z0, Z30
	VPADDW    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000003e0, BX
	JMP       int16AddScalarBlockLoop

int16AddScalarTailLoop:
	CMPQ      BX, $0x00000020
	JL        int16AddScalarDone
	VPADDW    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       int16AddScalarTailLoop

int16AddScalarDone:
	CMPQ      BX, $0x00000010
	JL        int16AddScalarDone1
	VPADDW    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

int16AddScalarDone1:
	CMPQ      BX, $0x00000008
	JL        int16AddScalarDone2
	VPADDW    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int16AddScalarDone2:
	RET

// func int32AddAvx512Asm(x []int32, y []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·int32AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int32AddBlockLoop:
	CMPQ      BX, $0x00000200
	JL        int32AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDD    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDD    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDD    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDD    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDD    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDD    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDD    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDD    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDD    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDD    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDD    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDD    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDD    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDD    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDD    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDD    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDD    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDD    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDD    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDD    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDD    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDD    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDD    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDD    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDD    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDD    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDD    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDD    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDD    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDD    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDD    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000200, BX
	JMP       int32AddBlockLoop

int32AddTailLoop:
	CMPQ      BX, $0x00000010
	JL        int32AddDone
	VMOVDQU32 (AX), Z0
	VPADDD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       int32AddTailLoop

int32AddDone:
	CMPQ      BX, $0x00000008
	JL        int32AddDone1
	VMOVDQU32 (AX), Y0
	VPADDD    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

int32AddDone1:
	CMPQ      BX, $0x00000004
	JL        int32AddDone2
	VMOVDQU32 (AX), X0
	VPADDD    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int32AddDone2:
	RET

// func int32AddScalarAvx512Asm(x int32, y []int32, r []int32)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·int32AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVL         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTD X0, Z0

int32AddScalarBlockLoop:
	CMPQ      BX, $0x000001f0
	JL        int32AddScalarTailLoop
	VPADDD    (CX), Z0, Z1
	VPADDD    64(CX), Z0, Z2
	VPADDD    128(CX), Z0, Z3
	VPADDD    192(CX), Z0, Z4
	VPADDD    256(CX), Z0, Z5
	VPADDD    320(CX), Z0, Z6
	VPADDD    384(CX), Z0, Z7
	VPADDD    448(CX), Z0, Z8
	VPADDD    512(CX), Z0, Z9
	VPADDD    576(CX), Z0, Z10
	VPADDD    640(CX), Z0, Z11
	VPADDD    704(CX), Z0, Z12
	VPADDD    768(CX), Z0, Z13
	VPADDD    832(CX), Z0, Z14
	VPADDD    896(CX), Z0, Z15
	VPADDD    960(CX), Z0, Z16
	VPADDD    1024(CX), Z0, Z17
	VPADDD    1088(CX), Z0, Z18
	VPADDD    1152(CX), Z0, Z19
	VPADDD    1216(CX), Z0, Z20
	VPADDD    1280(CX), Z0, Z21
	VPADDD    1344(CX), Z0, Z22
	VPADDD    1408(CX), Z0, Z23
	VPADDD    1472(CX), Z0, Z24
	VPADDD    1536(CX), Z0, Z25
	VPADDD    1600(CX), Z0, Z26
	VPADDD    1664(CX), Z0, Z27
	VPADDD    1728(CX), Z0, Z28
	VPADDD    1792(CX), Z0, Z29
	VPADDD    1856(CX), Z0, Z30
	VPADDD    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000001f0, BX
	JMP       int32AddScalarBlockLoop

int32AddScalarTailLoop:
	CMPQ      BX, $0x00000010
	JL        int32AddScalarDone
	VPADDD    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       int32AddScalarTailLoop

int32AddScalarDone:
	CMPQ      BX, $0x00000008
	JL        int32AddScalarDone1
	VPADDD    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

int32AddScalarDone1:
	CMPQ      BX, $0x00000004
	JL        int32AddScalarDone2
	VPADDD    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int32AddScalarDone2:
	RET

// func int64AddAvx512Asm(x []int64, y []int64, r []int64)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·int64AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

int64AddBlockLoop:
	CMPQ      BX, $0x00000100
	JL        int64AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDQ    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDQ    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDQ    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDQ    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDQ    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDQ    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDQ    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDQ    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDQ    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDQ    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDQ    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDQ    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDQ    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDQ    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDQ    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDQ    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDQ    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDQ    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDQ    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDQ    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDQ    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDQ    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDQ    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDQ    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDQ    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDQ    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDQ    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDQ    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDQ    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDQ    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDQ    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000100, BX
	JMP       int64AddBlockLoop

int64AddTailLoop:
	CMPQ      BX, $0x00000008
	JL        int64AddDone
	VMOVDQU32 (AX), Z0
	VPADDQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       int64AddTailLoop

int64AddDone:
	CMPQ      BX, $0x00000004
	JL        int64AddDone1
	VMOVDQU32 (AX), Y0
	VPADDQ    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

int64AddDone1:
	CMPQ      BX, $0x00000002
	JL        int64AddDone2
	VMOVDQU32 (AX), X0
	VPADDQ    (CX), X0, X0
	VMOVDQU32 X0, (DX)

int64AddDone2:
	RET

// func int64AddScalarAvx512Asm(x int64, y []int64, r []int64)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·int64AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVQ         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVQ         AX, X0
	VPBROADCASTQ X0, Z0

int64AddScalarBlockLoop:
	CMPQ      BX, $0x000000f8
	JL        int64AddScalarTailLoop
	VPADDQ    (CX), Z0, Z1
	VPADDQ    64(CX), Z0, Z2
	VPADDQ    128(CX), Z0, Z3
	VPADDQ    192(CX), Z0, Z4
	VPADDQ    256(CX), Z0, Z5
	VPADDQ    320(CX), Z0, Z6
	VPADDQ    384(CX), Z0, Z7
	VPADDQ    448(CX), Z0, Z8
	VPADDQ    512(CX), Z0, Z9
	VPADDQ    576(CX), Z0, Z10
	VPADDQ    640(CX), Z0, Z11
	VPADDQ    704(CX), Z0, Z12
	VPADDQ    768(CX), Z0, Z13
	VPADDQ    832(CX), Z0, Z14
	VPADDQ    896(CX), Z0, Z15
	VPADDQ    960(CX), Z0, Z16
	VPADDQ    1024(CX), Z0, Z17
	VPADDQ    1088(CX), Z0, Z18
	VPADDQ    1152(CX), Z0, Z19
	VPADDQ    1216(CX), Z0, Z20
	VPADDQ    1280(CX), Z0, Z21
	VPADDQ    1344(CX), Z0, Z22
	VPADDQ    1408(CX), Z0, Z23
	VPADDQ    1472(CX), Z0, Z24
	VPADDQ    1536(CX), Z0, Z25
	VPADDQ    1600(CX), Z0, Z26
	VPADDQ    1664(CX), Z0, Z27
	VPADDQ    1728(CX), Z0, Z28
	VPADDQ    1792(CX), Z0, Z29
	VPADDQ    1856(CX), Z0, Z30
	VPADDQ    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000000f8, BX
	JMP       int64AddScalarBlockLoop

int64AddScalarTailLoop:
	CMPQ      BX, $0x00000008
	JL        int64AddScalarDone
	VPADDQ    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       int64AddScalarTailLoop

int64AddScalarDone:
	CMPQ      BX, $0x00000004
	JL        int64AddScalarDone1
	VPADDQ    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

int64AddScalarDone1:
	CMPQ      BX, $0x00000002
	JL        int64AddScalarDone2
	VPADDQ    (CX), X0, X1
	VMOVDQU32 X1, (DX)

int64AddScalarDone2:
	RET

// func uint8AddAvx512Asm(x []uint8, y []uint8, r []uint8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·uint8AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint8AddBlockLoop:
	CMPQ      BX, $0x00000800
	JL        uint8AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDB    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDB    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDB    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDB    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDB    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDB    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDB    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDB    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDB    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDB    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDB    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDB    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDB    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDB    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDB    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDB    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDB    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDB    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDB    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDB    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDB    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDB    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDB    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDB    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDB    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDB    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDB    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDB    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDB    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDB    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDB    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000800, BX
	JMP       uint8AddBlockLoop

uint8AddTailLoop:
	CMPQ      BX, $0x00000040
	JL        uint8AddDone
	VMOVDQU32 (AX), Z0
	VPADDB    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       uint8AddTailLoop

uint8AddDone:
	CMPQ      BX, $0x00000020
	JL        uint8AddDone1
	VMOVDQU32 (AX), Y0
	VPADDB    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

uint8AddDone1:
	CMPQ      BX, $0x00000010
	JL        uint8AddDone2
	VMOVDQU32 (AX), X0
	VPADDB    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint8AddDone2:
	RET

// func uint8AddScalarAvx512Asm(x uint8, y []uint8, r []uint8)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·uint8AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVBLZX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTB X0, Z0

uint8AddScalarBlockLoop:
	CMPQ      BX, $0x000007c0
	JL        uint8AddScalarTailLoop
	VPADDB    (CX), Z0, Z1
	VPADDB    64(CX), Z0, Z2
	VPADDB    128(CX), Z0, Z3
	VPADDB    192(CX), Z0, Z4
	VPADDB    256(CX), Z0, Z5
	VPADDB    320(CX), Z0, Z6
	VPADDB    384(CX), Z0, Z7
	VPADDB    448(CX), Z0, Z8
	VPADDB    512(CX), Z0, Z9
	VPADDB    576(CX), Z0, Z10
	VPADDB    640(CX), Z0, Z11
	VPADDB    704(CX), Z0, Z12
	VPADDB    768(CX), Z0, Z13
	VPADDB    832(CX), Z0, Z14
	VPADDB    896(CX), Z0, Z15
	VPADDB    960(CX), Z0, Z16
	VPADDB    1024(CX), Z0, Z17
	VPADDB    1088(CX), Z0, Z18
	VPADDB    1152(CX), Z0, Z19
	VPADDB    1216(CX), Z0, Z20
	VPADDB    1280(CX), Z0, Z21
	VPADDB    1344(CX), Z0, Z22
	VPADDB    1408(CX), Z0, Z23
	VPADDB    1472(CX), Z0, Z24
	VPADDB    1536(CX), Z0, Z25
	VPADDB    1600(CX), Z0, Z26
	VPADDB    1664(CX), Z0, Z27
	VPADDB    1728(CX), Z0, Z28
	VPADDB    1792(CX), Z0, Z29
	VPADDB    1856(CX), Z0, Z30
	VPADDB    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000007c0, BX
	JMP       uint8AddScalarBlockLoop

uint8AddScalarTailLoop:
	CMPQ      BX, $0x00000040
	JL        uint8AddScalarDone
	VPADDB    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000040, BX
	JMP       uint8AddScalarTailLoop

uint8AddScalarDone:
	CMPQ      BX, $0x00000020
	JL        uint8AddScalarDone1
	VPADDB    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000020, BX

uint8AddScalarDone1:
	CMPQ      BX, $0x00000010
	JL        uint8AddScalarDone2
	VPADDB    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint8AddScalarDone2:
	RET

// func uint16AddAvx512Asm(x []uint16, y []uint16, r []uint16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL
TEXT ·uint16AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint16AddBlockLoop:
	CMPQ      BX, $0x00000400
	JL        uint16AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDW    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDW    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDW    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDW    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDW    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDW    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDW    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDW    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDW    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDW    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDW    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDW    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDW    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDW    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDW    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDW    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDW    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDW    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDW    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDW    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDW    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDW    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDW    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDW    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDW    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDW    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDW    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDW    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDW    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDW    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDW    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000400, BX
	JMP       uint16AddBlockLoop

uint16AddTailLoop:
	CMPQ      BX, $0x00000020
	JL        uint16AddDone
	VMOVDQU32 (AX), Z0
	VPADDW    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       uint16AddTailLoop

uint16AddDone:
	CMPQ      BX, $0x00000010
	JL        uint16AddDone1
	VMOVDQU32 (AX), Y0
	VPADDW    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

uint16AddDone1:
	CMPQ      BX, $0x00000008
	JL        uint16AddDone2
	VMOVDQU32 (AX), X0
	VPADDW    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint16AddDone2:
	RET

// func uint16AddScalarAvx512Asm(x uint16, y []uint16, r []uint16)
// Requires: AVX, AVX2, AVX512BW, AVX512F, AVX512VL, SSE2
TEXT ·uint16AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVWLZX      x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTW X0, Z0

uint16AddScalarBlockLoop:
	CMPQ      BX, $0x000003e0
	JL        uint16AddScalarTailLoop
	VPADDW    (CX), Z0, Z1
	VPADDW    64(CX), Z0, Z2
	VPADDW    128(CX), Z0, Z3
	VPADDW    192(CX), Z0, Z4
	VPADDW    256(CX), Z0, Z5
	VPADDW    320(CX), Z0, Z6
	VPADDW    384(CX), Z0, Z7
	VPADDW    448(CX), Z0, Z8
	VPADDW    512(CX), Z0, Z9
	VPADDW    576(CX), Z0, Z10
	VPADDW    640(CX), Z0, Z11
	VPADDW    704(CX), Z0, Z12
	VPADDW    768(CX), Z0, Z13
	VPADDW    832(CX), Z0, Z14
	VPADDW    896(CX), Z0, Z15
	VPADDW    960(CX), Z0, Z16
	VPADDW    1024(CX), Z0, Z17
	VPADDW    1088(CX), Z0, Z18
	VPADDW    1152(CX), Z0, Z19
	VPADDW    1216(CX), Z0, Z20
	VPADDW    1280(CX), Z0, Z21
	VPADDW    1344(CX), Z0, Z22
	VPADDW    1408(CX), Z0, Z23
	VPADDW    1472(CX), Z0, Z24
	VPADDW    1536(CX), Z0, Z25
	VPADDW    1600(CX), Z0, Z26
	VPADDW    1664(CX), Z0, Z27
	VPADDW    1728(CX), Z0, Z28
	VPADDW    1792(CX), Z0, Z29
	VPADDW    1856(CX), Z0, Z30
	VPADDW    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000003e0, BX
	JMP       uint16AddScalarBlockLoop

uint16AddScalarTailLoop:
	CMPQ      BX, $0x00000020
	JL        uint16AddScalarDone
	VPADDW    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000020, BX
	JMP       uint16AddScalarTailLoop

uint16AddScalarDone:
	CMPQ      BX, $0x00000010
	JL        uint16AddScalarDone1
	VPADDW    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000010, BX

uint16AddScalarDone1:
	CMPQ      BX, $0x00000008
	JL        uint16AddScalarDone2
	VPADDW    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint16AddScalarDone2:
	RET

// func uint32AddAvx512Asm(x []uint32, y []uint32, r []uint32)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·uint32AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint32AddBlockLoop:
	CMPQ      BX, $0x00000200
	JL        uint32AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDD    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDD    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDD    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDD    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDD    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDD    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDD    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDD    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDD    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDD    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDD    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDD    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDD    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDD    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDD    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDD    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDD    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDD    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDD    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDD    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDD    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDD    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDD    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDD    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDD    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDD    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDD    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDD    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDD    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDD    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDD    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000200, BX
	JMP       uint32AddBlockLoop

uint32AddTailLoop:
	CMPQ      BX, $0x00000010
	JL        uint32AddDone
	VMOVDQU32 (AX), Z0
	VPADDD    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       uint32AddTailLoop

uint32AddDone:
	CMPQ      BX, $0x00000008
	JL        uint32AddDone1
	VMOVDQU32 (AX), Y0
	VPADDD    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

uint32AddDone1:
	CMPQ      BX, $0x00000004
	JL        uint32AddDone2
	VMOVDQU32 (AX), X0
	VPADDD    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint32AddDone2:
	RET

// func uint32AddScalarAvx512Asm(x uint32, y []uint32, r []uint32)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·uint32AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVL         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVD         AX, X0
	VPBROADCASTD X0, Z0

uint32AddScalarBlockLoop:
	CMPQ      BX, $0x000001f0
	JL        uint32AddScalarTailLoop
	VPADDD    (CX), Z0, Z1
	VPADDD    64(CX), Z0, Z2
	VPADDD    128(CX), Z0, Z3
	VPADDD    192(CX), Z0, Z4
	VPADDD    256(CX), Z0, Z5
	VPADDD    320(CX), Z0, Z6
	VPADDD    384(CX), Z0, Z7
	VPADDD    448(CX), Z0, Z8
	VPADDD    512(CX), Z0, Z9
	VPADDD    576(CX), Z0, Z10
	VPADDD    640(CX), Z0, Z11
	VPADDD    704(CX), Z0, Z12
	VPADDD    768(CX), Z0, Z13
	VPADDD    832(CX), Z0, Z14
	VPADDD    896(CX), Z0, Z15
	VPADDD    960(CX), Z0, Z16
	VPADDD    1024(CX), Z0, Z17
	VPADDD    1088(CX), Z0, Z18
	VPADDD    1152(CX), Z0, Z19
	VPADDD    1216(CX), Z0, Z20
	VPADDD    1280(CX), Z0, Z21
	VPADDD    1344(CX), Z0, Z22
	VPADDD    1408(CX), Z0, Z23
	VPADDD    1472(CX), Z0, Z24
	VPADDD    1536(CX), Z0, Z25
	VPADDD    1600(CX), Z0, Z26
	VPADDD    1664(CX), Z0, Z27
	VPADDD    1728(CX), Z0, Z28
	VPADDD    1792(CX), Z0, Z29
	VPADDD    1856(CX), Z0, Z30
	VPADDD    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000001f0, BX
	JMP       uint32AddScalarBlockLoop

uint32AddScalarTailLoop:
	CMPQ      BX, $0x00000010
	JL        uint32AddScalarDone
	VPADDD    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000010, BX
	JMP       uint32AddScalarTailLoop

uint32AddScalarDone:
	CMPQ      BX, $0x00000008
	JL        uint32AddScalarDone1
	VPADDD    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000008, BX

uint32AddScalarDone1:
	CMPQ      BX, $0x00000004
	JL        uint32AddScalarDone2
	VPADDD    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint32AddScalarDone2:
	RET

// func uint64AddAvx512Asm(x []uint64, y []uint64, r []uint64)
// Requires: AVX, AVX2, AVX512F, AVX512VL
TEXT ·uint64AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

uint64AddBlockLoop:
	CMPQ      BX, $0x00000100
	JL        uint64AddTailLoop
	VMOVDQU32 (AX), Z0
	VMOVDQU32 64(AX), Z1
	VMOVDQU32 128(AX), Z2
	VMOVDQU32 192(AX), Z3
	VMOVDQU32 256(AX), Z4
	VMOVDQU32 320(AX), Z5
	VMOVDQU32 384(AX), Z6
	VMOVDQU32 448(AX), Z7
	VMOVDQU32 512(AX), Z8
	VMOVDQU32 576(AX), Z9
	VMOVDQU32 640(AX), Z10
	VMOVDQU32 704(AX), Z11
	VMOVDQU32 768(AX), Z12
	VMOVDQU32 832(AX), Z13
	VMOVDQU32 896(AX), Z14
	VMOVDQU32 960(AX), Z15
	VMOVDQU32 1024(AX), Z16
	VMOVDQU32 1088(AX), Z17
	VMOVDQU32 1152(AX), Z18
	VMOVDQU32 1216(AX), Z19
	VMOVDQU32 1280(AX), Z20
	VMOVDQU32 1344(AX), Z21
	VMOVDQU32 1408(AX), Z22
	VMOVDQU32 1472(AX), Z23
	VMOVDQU32 1536(AX), Z24
	VMOVDQU32 1600(AX), Z25
	VMOVDQU32 1664(AX), Z26
	VMOVDQU32 1728(AX), Z27
	VMOVDQU32 1792(AX), Z28
	VMOVDQU32 1856(AX), Z29
	VMOVDQU32 1920(AX), Z30
	VMOVDQU32 1984(AX), Z31
	VPADDQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	VPADDQ    64(CX), Z1, Z1
	VMOVDQU32 Z1, 64(DX)
	VPADDQ    128(CX), Z2, Z2
	VMOVDQU32 Z2, 128(DX)
	VPADDQ    192(CX), Z3, Z3
	VMOVDQU32 Z3, 192(DX)
	VPADDQ    256(CX), Z4, Z4
	VMOVDQU32 Z4, 256(DX)
	VPADDQ    320(CX), Z5, Z5
	VMOVDQU32 Z5, 320(DX)
	VPADDQ    384(CX), Z6, Z6
	VMOVDQU32 Z6, 384(DX)
	VPADDQ    448(CX), Z7, Z7
	VMOVDQU32 Z7, 448(DX)
	VPADDQ    512(CX), Z8, Z8
	VMOVDQU32 Z8, 512(DX)
	VPADDQ    576(CX), Z9, Z9
	VMOVDQU32 Z9, 576(DX)
	VPADDQ    640(CX), Z10, Z10
	VMOVDQU32 Z10, 640(DX)
	VPADDQ    704(CX), Z11, Z11
	VMOVDQU32 Z11, 704(DX)
	VPADDQ    768(CX), Z12, Z12
	VMOVDQU32 Z12, 768(DX)
	VPADDQ    832(CX), Z13, Z13
	VMOVDQU32 Z13, 832(DX)
	VPADDQ    896(CX), Z14, Z14
	VMOVDQU32 Z14, 896(DX)
	VPADDQ    960(CX), Z15, Z15
	VMOVDQU32 Z15, 960(DX)
	VPADDQ    1024(CX), Z16, Z16
	VMOVDQU32 Z16, 1024(DX)
	VPADDQ    1088(CX), Z17, Z17
	VMOVDQU32 Z17, 1088(DX)
	VPADDQ    1152(CX), Z18, Z18
	VMOVDQU32 Z18, 1152(DX)
	VPADDQ    1216(CX), Z19, Z19
	VMOVDQU32 Z19, 1216(DX)
	VPADDQ    1280(CX), Z20, Z20
	VMOVDQU32 Z20, 1280(DX)
	VPADDQ    1344(CX), Z21, Z21
	VMOVDQU32 Z21, 1344(DX)
	VPADDQ    1408(CX), Z22, Z22
	VMOVDQU32 Z22, 1408(DX)
	VPADDQ    1472(CX), Z23, Z23
	VMOVDQU32 Z23, 1472(DX)
	VPADDQ    1536(CX), Z24, Z24
	VMOVDQU32 Z24, 1536(DX)
	VPADDQ    1600(CX), Z25, Z25
	VMOVDQU32 Z25, 1600(DX)
	VPADDQ    1664(CX), Z26, Z26
	VMOVDQU32 Z26, 1664(DX)
	VPADDQ    1728(CX), Z27, Z27
	VMOVDQU32 Z27, 1728(DX)
	VPADDQ    1792(CX), Z28, Z28
	VMOVDQU32 Z28, 1792(DX)
	VPADDQ    1856(CX), Z29, Z29
	VMOVDQU32 Z29, 1856(DX)
	VPADDQ    1920(CX), Z30, Z30
	VMOVDQU32 Z30, 1920(DX)
	VPADDQ    1984(CX), Z31, Z31
	VMOVDQU32 Z31, 1984(DX)
	ADDQ      $0x00000800, AX
	ADDQ      $0x00000800, CX
	ADDQ      $0x00000800, DX
	SUBQ      $0x00000100, BX
	JMP       uint64AddBlockLoop

uint64AddTailLoop:
	CMPQ      BX, $0x00000008
	JL        uint64AddDone
	VMOVDQU32 (AX), Z0
	VPADDQ    (CX), Z0, Z0
	VMOVDQU32 Z0, (DX)
	ADDQ      $0x00000040, AX
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       uint64AddTailLoop

uint64AddDone:
	CMPQ      BX, $0x00000004
	JL        uint64AddDone1
	VMOVDQU32 (AX), Y0
	VPADDQ    (CX), Y0, Y0
	VMOVDQU32 Y0, (DX)
	ADDQ      $0x00000020, AX
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

uint64AddDone1:
	CMPQ      BX, $0x00000002
	JL        uint64AddDone2
	VMOVDQU32 (AX), X0
	VPADDQ    (CX), X0, X0
	VMOVDQU32 X0, (DX)

uint64AddDone2:
	RET

// func uint64AddScalarAvx512Asm(x uint64, y []uint64, r []uint64)
// Requires: AVX, AVX2, AVX512F, AVX512VL, SSE2
TEXT ·uint64AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVQ         x+0(FP), AX
	MOVQ         y_base+8(FP), CX
	MOVQ         r_base+32(FP), DX
	MOVQ         y_len+16(FP), BX
	MOVQ         AX, X0
	VPBROADCASTQ X0, Z0

uint64AddScalarBlockLoop:
	CMPQ      BX, $0x000000f8
	JL        uint64AddScalarTailLoop
	VPADDQ    (CX), Z0, Z1
	VPADDQ    64(CX), Z0, Z2
	VPADDQ    128(CX), Z0, Z3
	VPADDQ    192(CX), Z0, Z4
	VPADDQ    256(CX), Z0, Z5
	VPADDQ    320(CX), Z0, Z6
	VPADDQ    384(CX), Z0, Z7
	VPADDQ    448(CX), Z0, Z8
	VPADDQ    512(CX), Z0, Z9
	VPADDQ    576(CX), Z0, Z10
	VPADDQ    640(CX), Z0, Z11
	VPADDQ    704(CX), Z0, Z12
	VPADDQ    768(CX), Z0, Z13
	VPADDQ    832(CX), Z0, Z14
	VPADDQ    896(CX), Z0, Z15
	VPADDQ    960(CX), Z0, Z16
	VPADDQ    1024(CX), Z0, Z17
	VPADDQ    1088(CX), Z0, Z18
	VPADDQ    1152(CX), Z0, Z19
	VPADDQ    1216(CX), Z0, Z20
	VPADDQ    1280(CX), Z0, Z21
	VPADDQ    1344(CX), Z0, Z22
	VPADDQ    1408(CX), Z0, Z23
	VPADDQ    1472(CX), Z0, Z24
	VPADDQ    1536(CX), Z0, Z25
	VPADDQ    1600(CX), Z0, Z26
	VPADDQ    1664(CX), Z0, Z27
	VPADDQ    1728(CX), Z0, Z28
	VPADDQ    1792(CX), Z0, Z29
	VPADDQ    1856(CX), Z0, Z30
	VPADDQ    1920(CX), Z0, Z31
	VMOVDQU32 Z1, (DX)
	VMOVDQU32 Z2, 64(DX)
	VMOVDQU32 Z3, 128(DX)
	VMOVDQU32 Z4, 192(DX)
	VMOVDQU32 Z5, 256(DX)
	VMOVDQU32 Z6, 320(DX)
	VMOVDQU32 Z7, 384(DX)
	VMOVDQU32 Z8, 448(DX)
	VMOVDQU32 Z9, 512(DX)
	VMOVDQU32 Z10, 576(DX)
	VMOVDQU32 Z11, 640(DX)
	VMOVDQU32 Z12, 704(DX)
	VMOVDQU32 Z13, 768(DX)
	VMOVDQU32 Z14, 832(DX)
	VMOVDQU32 Z15, 896(DX)
	VMOVDQU32 Z16, 960(DX)
	VMOVDQU32 Z17, 1024(DX)
	VMOVDQU32 Z18, 1088(DX)
	VMOVDQU32 Z19, 1152(DX)
	VMOVDQU32 Z20, 1216(DX)
	VMOVDQU32 Z21, 1280(DX)
	VMOVDQU32 Z22, 1344(DX)
	VMOVDQU32 Z23, 1408(DX)
	VMOVDQU32 Z24, 1472(DX)
	VMOVDQU32 Z25, 1536(DX)
	VMOVDQU32 Z26, 1600(DX)
	VMOVDQU32 Z27, 1664(DX)
	VMOVDQU32 Z28, 1728(DX)
	VMOVDQU32 Z29, 1792(DX)
	VMOVDQU32 Z30, 1856(DX)
	VMOVDQU32 Z31, 1920(DX)
	ADDQ      $0x000007c0, CX
	ADDQ      $0x000007c0, DX
	SUBQ      $0x000000f8, BX
	JMP       uint64AddScalarBlockLoop

uint64AddScalarTailLoop:
	CMPQ      BX, $0x00000008
	JL        uint64AddScalarDone
	VPADDQ    (CX), Z0, Z1
	VMOVDQU32 Z1, (DX)
	ADDQ      $0x00000040, CX
	ADDQ      $0x00000040, DX
	SUBQ      $0x00000008, BX
	JMP       uint64AddScalarTailLoop

uint64AddScalarDone:
	CMPQ      BX, $0x00000004
	JL        uint64AddScalarDone1
	VPADDQ    (CX), Y0, Y1
	VMOVDQU32 Y1, (DX)
	ADDQ      $0x00000020, CX
	ADDQ      $0x00000020, DX
	SUBQ      $0x00000004, BX

uint64AddScalarDone1:
	CMPQ      BX, $0x00000002
	JL        uint64AddScalarDone2
	VPADDQ    (CX), X0, X1
	VMOVDQU32 X1, (DX)

uint64AddScalarDone2:
	RET

// func float32AddAvx512Asm(x []float32, y []float32, r []float32)
// Requires: AVX, AVX512F
TEXT ·float32AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

float32AddBlockLoop:
	CMPQ    BX, $0x00000200
	JL      float32AddTailLoop
	VMOVUPS (AX), Z0
	VMOVUPS 64(AX), Z1
	VMOVUPS 128(AX), Z2
	VMOVUPS 192(AX), Z3
	VMOVUPS 256(AX), Z4
	VMOVUPS 320(AX), Z5
	VMOVUPS 384(AX), Z6
	VMOVUPS 448(AX), Z7
	VMOVUPS 512(AX), Z8
	VMOVUPS 576(AX), Z9
	VMOVUPS 640(AX), Z10
	VMOVUPS 704(AX), Z11
	VMOVUPS 768(AX), Z12
	VMOVUPS 832(AX), Z13
	VMOVUPS 896(AX), Z14
	VMOVUPS 960(AX), Z15
	VMOVUPS 1024(AX), Z16
	VMOVUPS 1088(AX), Z17
	VMOVUPS 1152(AX), Z18
	VMOVUPS 1216(AX), Z19
	VMOVUPS 1280(AX), Z20
	VMOVUPS 1344(AX), Z21
	VMOVUPS 1408(AX), Z22
	VMOVUPS 1472(AX), Z23
	VMOVUPS 1536(AX), Z24
	VMOVUPS 1600(AX), Z25
	VMOVUPS 1664(AX), Z26
	VMOVUPS 1728(AX), Z27
	VMOVUPS 1792(AX), Z28
	VMOVUPS 1856(AX), Z29
	VMOVUPS 1920(AX), Z30
	VMOVUPS 1984(AX), Z31
	VADDPS  (CX), Z0, Z0
	VMOVUPS Z0, (DX)
	VADDPS  64(CX), Z1, Z1
	VMOVUPS Z1, 64(DX)
	VADDPS  128(CX), Z2, Z2
	VMOVUPS Z2, 128(DX)
	VADDPS  192(CX), Z3, Z3
	VMOVUPS Z3, 192(DX)
	VADDPS  256(CX), Z4, Z4
	VMOVUPS Z4, 256(DX)
	VADDPS  320(CX), Z5, Z5
	VMOVUPS Z5, 320(DX)
	VADDPS  384(CX), Z6, Z6
	VMOVUPS Z6, 384(DX)
	VADDPS  448(CX), Z7, Z7
	VMOVUPS Z7, 448(DX)
	VADDPS  512(CX), Z8, Z8
	VMOVUPS Z8, 512(DX)
	VADDPS  576(CX), Z9, Z9
	VMOVUPS Z9, 576(DX)
	VADDPS  640(CX), Z10, Z10
	VMOVUPS Z10, 640(DX)
	VADDPS  704(CX), Z11, Z11
	VMOVUPS Z11, 704(DX)
	VADDPS  768(CX), Z12, Z12
	VMOVUPS Z12, 768(DX)
	VADDPS  832(CX), Z13, Z13
	VMOVUPS Z13, 832(DX)
	VADDPS  896(CX), Z14, Z14
	VMOVUPS Z14, 896(DX)
	VADDPS  960(CX), Z15, Z15
	VMOVUPS Z15, 960(DX)
	VADDPS  1024(CX), Z16, Z16
	VMOVUPS Z16, 1024(DX)
	VADDPS  1088(CX), Z17, Z17
	VMOVUPS Z17, 1088(DX)
	VADDPS  1152(CX), Z18, Z18
	VMOVUPS Z18, 1152(DX)
	VADDPS  1216(CX), Z19, Z19
	VMOVUPS Z19, 1216(DX)
	VADDPS  1280(CX), Z20, Z20
	VMOVUPS Z20, 1280(DX)
	VADDPS  1344(CX), Z21, Z21
	VMOVUPS Z21, 1344(DX)
	VADDPS  1408(CX), Z22, Z22
	VMOVUPS Z22, 1408(DX)
	VADDPS  1472(CX), Z23, Z23
	VMOVUPS Z23, 1472(DX)
	VADDPS  1536(CX), Z24, Z24
	VMOVUPS Z24, 1536(DX)
	VADDPS  1600(CX), Z25, Z25
	VMOVUPS Z25, 1600(DX)
	VADDPS  1664(CX), Z26, Z26
	VMOVUPS Z26, 1664(DX)
	VADDPS  1728(CX), Z27, Z27
	VMOVUPS Z27, 1728(DX)
	VADDPS  1792(CX), Z28, Z28
	VMOVUPS Z28, 1792(DX)
	VADDPS  1856(CX), Z29, Z29
	VMOVUPS Z29, 1856(DX)
	VADDPS  1920(CX), Z30, Z30
	VMOVUPS Z30, 1920(DX)
	VADDPS  1984(CX), Z31, Z31
	VMOVUPS Z31, 1984(DX)
	ADDQ    $0x00000800, AX
	ADDQ    $0x00000800, CX
	ADDQ    $0x00000800, DX
	SUBQ    $0x00000200, BX
	JMP     float32AddBlockLoop

float32AddTailLoop:
	CMPQ    BX, $0x00000010
	JL      float32AddDone
	VMOVUPS (AX), Z0
	VADDPS  (CX), Z0, Z0
	VMOVUPS Z0, (DX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	ADDQ    $0x00000040, DX
	SUBQ    $0x00000010, BX
	JMP     float32AddTailLoop

float32AddDone:
	CMPQ    BX, $0x00000008
	JL      float32AddDone1
	VMOVUPS (AX), Y0
	VADDPS  (CX), Y0, Y0
	VMOVUPS Y0, (DX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	ADDQ    $0x00000020, DX
	SUBQ    $0x00000008, BX

float32AddDone1:
	CMPQ    BX, $0x00000004
	JL      float32AddDone2
	VMOVUPS (AX), X0
	VADDPS  (CX), X0, X0
	VMOVUPS X0, (DX)

float32AddDone2:
	RET

// func float32AddScalarAvx512Asm(x float32, y []float32, r []float32)
// Requires: AVX, AVX512F, SSE
TEXT ·float32AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVSS        x+0(FP), X0
	MOVQ         y_base+8(FP), AX
	MOVQ         r_base+32(FP), CX
	MOVQ         y_len+16(FP), DX
	VBROADCASTSS X0, Z0

float32AddScalarBlockLoop:
	CMPQ    DX, $0x000001f0
	JL      float32AddScalarTailLoop
	VADDPS  (AX), Z0, Z1
	VADDPS  64(AX), Z0, Z2
	VADDPS  128(AX), Z0, Z3
	VADDPS  192(AX), Z0, Z4
	VADDPS  256(AX), Z0, Z5
	VADDPS  320(AX), Z0, Z6
	VADDPS  384(AX), Z0, Z7
	VADDPS  448(AX), Z0, Z8
	VADDPS  512(AX), Z0, Z9
	VADDPS  576(AX), Z0, Z10
	VADDPS  640(AX), Z0, Z11
	VADDPS  704(AX), Z0, Z12
	VADDPS  768(AX), Z0, Z13
	VADDPS  832(AX), Z0, Z14
	VADDPS  896(AX), Z0, Z15
	VADDPS  960(AX), Z0, Z16
	VADDPS  1024(AX), Z0, Z17
	VADDPS  1088(AX), Z0, Z18
	VADDPS  1152(AX), Z0, Z19
	VADDPS  1216(AX), Z0, Z20
	VADDPS  1280(AX), Z0, Z21
	VADDPS  1344(AX), Z0, Z22
	VADDPS  1408(AX), Z0, Z23
	VADDPS  1472(AX), Z0, Z24
	VADDPS  1536(AX), Z0, Z25
	VADDPS  1600(AX), Z0, Z26
	VADDPS  1664(AX), Z0, Z27
	VADDPS  1728(AX), Z0, Z28
	VADDPS  1792(AX), Z0, Z29
	VADDPS  1856(AX), Z0, Z30
	VADDPS  1920(AX), Z0, Z31
	VMOVUPS Z1, (CX)
	VMOVUPS Z2, 64(CX)
	VMOVUPS Z3, 128(CX)
	VMOVUPS Z4, 192(CX)
	VMOVUPS Z5, 256(CX)
	VMOVUPS Z6, 320(CX)
	VMOVUPS Z7, 384(CX)
	VMOVUPS Z8, 448(CX)
	VMOVUPS Z9, 512(CX)
	VMOVUPS Z10, 576(CX)
	VMOVUPS Z11, 640(CX)
	VMOVUPS Z12, 704(CX)
	VMOVUPS Z13, 768(CX)
	VMOVUPS Z14, 832(CX)
	VMOVUPS Z15, 896(CX)
	VMOVUPS Z16, 960(CX)
	VMOVUPS Z17, 1024(CX)
	VMOVUPS Z18, 1088(CX)
	VMOVUPS Z19, 1152(CX)
	VMOVUPS Z20, 1216(CX)
	VMOVUPS Z21, 1280(CX)
	VMOVUPS Z22, 1344(CX)
	VMOVUPS Z23, 1408(CX)
	VMOVUPS Z24, 1472(CX)
	VMOVUPS Z25, 1536(CX)
	VMOVUPS Z26, 1600(CX)
	VMOVUPS Z27, 1664(CX)
	VMOVUPS Z28, 1728(CX)
	VMOVUPS Z29, 1792(CX)
	VMOVUPS Z30, 1856(CX)
	VMOVUPS Z31, 1920(CX)
	ADDQ    $0x000007c0, AX
	ADDQ    $0x000007c0, CX
	SUBQ    $0x000001f0, DX
	JMP     float32AddScalarBlockLoop

float32AddScalarTailLoop:
	CMPQ    DX, $0x00000010
	JL      float32AddScalarDone
	VADDPS  (AX), Z0, Z1
	VMOVUPS Z1, (CX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	SUBQ    $0x00000010, DX
	JMP     float32AddScalarTailLoop

float32AddScalarDone:
	CMPQ    DX, $0x00000008
	JL      float32AddScalarDone1
	VADDPS  (AX), Y0, Y1
	VMOVUPS Y1, (CX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	SUBQ    $0x00000008, DX

float32AddScalarDone1:
	CMPQ    DX, $0x00000004
	JL      float32AddScalarDone2
	VADDPS  (AX), X0, X1
	VMOVUPS X1, (CX)

float32AddScalarDone2:
	RET

// func float64AddAvx512Asm(x []float64, y []float64, r []float64)
// Requires: AVX, AVX512F
TEXT ·float64AddAvx512Asm(SB), NOSPLIT, $0-72
	MOVQ x_base+0(FP), AX
	MOVQ y_base+24(FP), CX
	MOVQ r_base+48(FP), DX
	MOVQ x_len+8(FP), BX

float64AddBlockLoop:
	CMPQ    BX, $0x00000100
	JL      float64AddTailLoop
	VMOVUPD (AX), Z0
	VMOVUPD 64(AX), Z1
	VMOVUPD 128(AX), Z2
	VMOVUPD 192(AX), Z3
	VMOVUPD 256(AX), Z4
	VMOVUPD 320(AX), Z5
	VMOVUPD 384(AX), Z6
	VMOVUPD 448(AX), Z7
	VMOVUPD 512(AX), Z8
	VMOVUPD 576(AX), Z9
	VMOVUPD 640(AX), Z10
	VMOVUPD 704(AX), Z11
	VMOVUPD 768(AX), Z12
	VMOVUPD 832(AX), Z13
	VMOVUPD 896(AX), Z14
	VMOVUPD 960(AX), Z15
	VMOVUPD 1024(AX), Z16
	VMOVUPD 1088(AX), Z17
	VMOVUPD 1152(AX), Z18
	VMOVUPD 1216(AX), Z19
	VMOVUPD 1280(AX), Z20
	VMOVUPD 1344(AX), Z21
	VMOVUPD 1408(AX), Z22
	VMOVUPD 1472(AX), Z23
	VMOVUPD 1536(AX), Z24
	VMOVUPD 1600(AX), Z25
	VMOVUPD 1664(AX), Z26
	VMOVUPD 1728(AX), Z27
	VMOVUPD 1792(AX), Z28
	VMOVUPD 1856(AX), Z29
	VMOVUPD 1920(AX), Z30
	VMOVUPD 1984(AX), Z31
	VADDPD  (CX), Z0, Z0
	VMOVUPD Z0, (DX)
	VADDPD  64(CX), Z1, Z1
	VMOVUPD Z1, 64(DX)
	VADDPD  128(CX), Z2, Z2
	VMOVUPD Z2, 128(DX)
	VADDPD  192(CX), Z3, Z3
	VMOVUPD Z3, 192(DX)
	VADDPD  256(CX), Z4, Z4
	VMOVUPD Z4, 256(DX)
	VADDPD  320(CX), Z5, Z5
	VMOVUPD Z5, 320(DX)
	VADDPD  384(CX), Z6, Z6
	VMOVUPD Z6, 384(DX)
	VADDPD  448(CX), Z7, Z7
	VMOVUPD Z7, 448(DX)
	VADDPD  512(CX), Z8, Z8
	VMOVUPD Z8, 512(DX)
	VADDPD  576(CX), Z9, Z9
	VMOVUPD Z9, 576(DX)
	VADDPD  640(CX), Z10, Z10
	VMOVUPD Z10, 640(DX)
	VADDPD  704(CX), Z11, Z11
	VMOVUPD Z11, 704(DX)
	VADDPD  768(CX), Z12, Z12
	VMOVUPD Z12, 768(DX)
	VADDPD  832(CX), Z13, Z13
	VMOVUPD Z13, 832(DX)
	VADDPD  896(CX), Z14, Z14
	VMOVUPD Z14, 896(DX)
	VADDPD  960(CX), Z15, Z15
	VMOVUPD Z15, 960(DX)
	VADDPD  1024(CX), Z16, Z16
	VMOVUPD Z16, 1024(DX)
	VADDPD  1088(CX), Z17, Z17
	VMOVUPD Z17, 1088(DX)
	VADDPD  1152(CX), Z18, Z18
	VMOVUPD Z18, 1152(DX)
	VADDPD  1216(CX), Z19, Z19
	VMOVUPD Z19, 1216(DX)
	VADDPD  1280(CX), Z20, Z20
	VMOVUPD Z20, 1280(DX)
	VADDPD  1344(CX), Z21, Z21
	VMOVUPD Z21, 1344(DX)
	VADDPD  1408(CX), Z22, Z22
	VMOVUPD Z22, 1408(DX)
	VADDPD  1472(CX), Z23, Z23
	VMOVUPD Z23, 1472(DX)
	VADDPD  1536(CX), Z24, Z24
	VMOVUPD Z24, 1536(DX)
	VADDPD  1600(CX), Z25, Z25
	VMOVUPD Z25, 1600(DX)
	VADDPD  1664(CX), Z26, Z26
	VMOVUPD Z26, 1664(DX)
	VADDPD  1728(CX), Z27, Z27
	VMOVUPD Z27, 1728(DX)
	VADDPD  1792(CX), Z28, Z28
	VMOVUPD Z28, 1792(DX)
	VADDPD  1856(CX), Z29, Z29
	VMOVUPD Z29, 1856(DX)
	VADDPD  1920(CX), Z30, Z30
	VMOVUPD Z30, 1920(DX)
	VADDPD  1984(CX), Z31, Z31
	VMOVUPD Z31, 1984(DX)
	ADDQ    $0x00000800, AX
	ADDQ    $0x00000800, CX
	ADDQ    $0x00000800, DX
	SUBQ    $0x00000100, BX
	JMP     float64AddBlockLoop

float64AddTailLoop:
	CMPQ    BX, $0x00000008
	JL      float64AddDone
	VMOVUPD (AX), Z0
	VADDPD  (CX), Z0, Z0
	VMOVUPD Z0, (DX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	ADDQ    $0x00000040, DX
	SUBQ    $0x00000008, BX
	JMP     float64AddTailLoop

float64AddDone:
	CMPQ    BX, $0x00000004
	JL      float64AddDone1
	VMOVUPD (AX), Y0
	VADDPD  (CX), Y0, Y0
	VMOVUPD Y0, (DX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	ADDQ    $0x00000020, DX
	SUBQ    $0x00000004, BX

float64AddDone1:
	CMPQ    BX, $0x00000002
	JL      float64AddDone2
	VMOVUPD (AX), X0
	VADDPD  (CX), X0, X0
	VMOVUPD X0, (DX)

float64AddDone2:
	RET

// func float64AddScalarAvx512Asm(x float64, y []float64, r []float64)
// Requires: AVX, AVX512F, SSE2
TEXT ·float64AddScalarAvx512Asm(SB), NOSPLIT, $0-56
	MOVSD        x+0(FP), X0
	MOVQ         y_base+8(FP), AX
	MOVQ         r_base+32(FP), CX
	MOVQ         y_len+16(FP), DX
	VBROADCASTSD X0, Z0

float64AddScalarBlockLoop:
	CMPQ    DX, $0x000000f8
	JL      float64AddScalarTailLoop
	VADDPD  (AX), Z0, Z1
	VADDPD  64(AX), Z0, Z2
	VADDPD  128(AX), Z0, Z3
	VADDPD  192(AX), Z0, Z4
	VADDPD  256(AX), Z0, Z5
	VADDPD  320(AX), Z0, Z6
	VADDPD  384(AX), Z0, Z7
	VADDPD  448(AX), Z0, Z8
	VADDPD  512(AX), Z0, Z9
	VADDPD  576(AX), Z0, Z10
	VADDPD  640(AX), Z0, Z11
	VADDPD  704(AX), Z0, Z12
	VADDPD  768(AX), Z0, Z13
	VADDPD  832(AX), Z0, Z14
	VADDPD  896(AX), Z0, Z15
	VADDPD  960(AX), Z0, Z16
	VADDPD  1024(AX), Z0, Z17
	VADDPD  1088(AX), Z0, Z18
	VADDPD  1152(AX), Z0, Z19
	VADDPD  1216(AX), Z0, Z20
	VADDPD  1280(AX), Z0, Z21
	VADDPD  1344(AX), Z0, Z22
	VADDPD  1408(AX), Z0, Z23
	VADDPD  1472(AX), Z0, Z24
	VADDPD  1536(AX), Z0, Z25
	VADDPD  1600(AX), Z0, Z26
	VADDPD  1664(AX), Z0, Z27
	VADDPD  1728(AX), Z0, Z28
	VADDPD  1792(AX), Z0, Z29
	VADDPD  1856(AX), Z0, Z30
	VADDPD  1920(AX), Z0, Z31
	VMOVUPD Z1, (CX)
	VMOVUPD Z2, 64(CX)
	VMOVUPD Z3, 128(CX)
	VMOVUPD Z4, 192(CX)
	VMOVUPD Z5, 256(CX)
	VMOVUPD Z6, 320(CX)
	VMOVUPD Z7, 384(CX)
	VMOVUPD Z8, 448(CX)
	VMOVUPD Z9, 512(CX)
	VMOVUPD Z10, 576(CX)
	VMOVUPD Z11, 640(CX)
	VMOVUPD Z12, 704(CX)
	VMOVUPD Z13, 768(CX)
	VMOVUPD Z14, 832(CX)
	VMOVUPD Z15, 896(CX)
	VMOVUPD Z16, 960(CX)
	VMOVUPD Z17, 1024(CX)
	VMOVUPD Z18, 1088(CX)
	VMOVUPD Z19, 1152(CX)
	VMOVUPD Z20, 1216(CX)
	VMOVUPD Z21, 1280(CX)
	VMOVUPD Z22, 1344(CX)
	VMOVUPD Z23, 1408(CX)
	VMOVUPD Z24, 1472(CX)
	VMOVUPD Z25, 1536(CX)
	VMOVUPD Z26, 1600(CX)
	VMOVUPD Z27, 1664(CX)
	VMOVUPD Z28, 1728(CX)
	VMOVUPD Z29, 1792(CX)
	VMOVUPD Z30, 1856(CX)
	VMOVUPD Z31, 1920(CX)
	ADDQ    $0x000007c0, AX
	ADDQ    $0x000007c0, CX
	SUBQ    $0x000000f8, DX
	JMP     float64AddScalarBlockLoop

float64AddScalarTailLoop:
	CMPQ    DX, $0x00000008
	JL      float64AddScalarDone
	VADDPD  (AX), Z0, Z1
	VMOVUPD Z1, (CX)
	ADDQ    $0x00000040, AX
	ADDQ    $0x00000040, CX
	SUBQ    $0x00000008, DX
	JMP     float64AddScalarTailLoop

float64AddScalarDone:
	CMPQ    DX, $0x00000004
	JL      float64AddScalarDone1
	VADDPD  (AX), Y0, Y1
	VMOVUPD Y1, (CX)
	ADDQ    $0x00000020, AX
	ADDQ    $0x00000020, CX
	SUBQ    $0x00000004, DX

float64AddScalarDone1:
	CMPQ    DX, $0x00000002
	JL      float64AddScalarDone2
	VADDPD  (AX), X0, X1
	VMOVUPD X1, (CX)

float64AddScalarDone2:
	RET
